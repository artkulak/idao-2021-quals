{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# IMPORT LIBS\n",
    "#####################\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import io, transform\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from sklearn.metrics import roc_auc_score, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import albumentations as A\n",
    "import cv2\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "\n",
    "#####################\n",
    "# SET CONSTANTS\n",
    "#####################\n",
    "\n",
    "INPUT_PATH = Path('../input')\n",
    "OUTPUT_PATH = Path('../output')\n",
    "TRAIN_PATH = INPUT_PATH / 'idao_dataset' / 'train'\n",
    "PRIVATE_PATH = INPUT_PATH / 'idao_dataset' / 'private_test'\n",
    "PUBLIC_PATH = INPUT_PATH / 'idao_dataset' / 'public_test'\n",
    "\n",
    "RANDOM_SEED = 4444\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "existing-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    BATCH_SIZE = 32\n",
    "    TRAINING_EPOCHS = 150\n",
    "    VALIDATION_STEPS_PER_EPOCH = 5\n",
    "    VALIDATION_EPOCHS = 10\n",
    "    STEPS_PER_EPOCH = 30\n",
    "    EARLY_STOP_PATIENCE = 5\n",
    "    \n",
    "    \n",
    "    # Declare an augmentation pipeline\n",
    "    train_transform = A.Compose([\n",
    "        #A.HorizontalFlip(p=0.5),\n",
    "        A.Cutout(num_holes=4, max_h_size=8, max_w_size=8, p=0.3),\n",
    "        A.OneOf([A.RandomContrast(),\n",
    "             A.RandomGamma(),\n",
    "             A.RandomBrightness()],p=0.2),\n",
    "        A.OneOf([A.Blur(p = 0.3),\n",
    "             A.GaussNoise(p=0.3)\n",
    "                ],p=0.5),\n",
    "        A.CLAHE(clip_limit=4, tile_grid_size=(8,8), always_apply=False, p=0.3),\n",
    "    ],)\n",
    "    \n",
    "    validation_transform = A.Compose([\n",
    "    ],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "alternative-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(img_path):\n",
    "    if len(img_path.split('_')) == 18:\n",
    "        particle_class = 0 # ER\n",
    "        particle_energy = int(img_path.split('_')[7])\n",
    "    else:\n",
    "        particle_class = 1 # HE\n",
    "        particle_energy = int(img_path.split('_')[8])\n",
    "    return [img_path, particle_class, particle_energy]\n",
    "\n",
    "images = glob.glob(str(TRAIN_PATH / '**/*.png'), recursive=True)\n",
    "images = pd.DataFrame(map(getFeatures, images))\n",
    "images.columns = ['path', 'class', 'energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "lasting-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# EXTRACT TEST\n",
    "#################\n",
    "\n",
    "# HE - 0, ER - 1\n",
    "\n",
    "he_test_idx = list(images[(images['class'] == 0) & (images['energy'].apply(lambda x: x in [1, 6, 20]))].index)\n",
    "er_test_idx = list(images[(images['class'] == 1) & (images['energy'].apply(lambda x: x in [3, 10, 30]))].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "federal-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write this to a separate folder\n",
    "\n",
    "# 0 - [:750]\n",
    "# 1 - [750:1502]\n",
    "# 0 - [1502:7531]\n",
    "# 1 - [7531:]\n",
    "\n",
    "import glob\n",
    "private_test = glob.glob(str(PRIVATE_PATH / '**/*.png'), recursive=True)\n",
    "public_test = glob.glob(str(PUBLIC_PATH / '**/*.png'), recursive=True)\n",
    "\n",
    "sample_submission = pd.read_csv(INPUT_PATH / 'track1_leak.csv')\n",
    "private_ids = [t.split('/')[-1].split('.')[0] for t in private_test]\n",
    "public_ids = [t.split('/')[-1].split('.')[0] for t in public_test]\n",
    "\n",
    "sample_submission['path'] = sample_submission['id'].apply(lambda x: PRIVATE_PATH / f'{x}.png' if x in private_ids else PUBLIC_PATH / f'{x}.png').map(str)\n",
    "sample_submission.iloc[:750, 1] = 0\n",
    "sample_submission.iloc[750:1502, 1] = 1\n",
    "sample_submission.iloc[1502:7531, 1] = 0\n",
    "sample_submission.iloc[7531:, 1] = 1\n",
    "\n",
    "sample_submission = sample_submission.iloc[1502:].reset_index(drop = True)\n",
    "\n",
    "images_leak = pd.DataFrame(np.array([sample_submission.iloc[:, 3].values, sample_submission.iloc[:, 1].values, sample_submission.iloc[:, 2].values]).T)\n",
    "images_leak.columns = ['path', 'class', 'energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "valued-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.concat([images, images_leak]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "banner-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = he_test_idx + er_test_idx\n",
    "test_images = images.iloc[test_idx]\n",
    "images = images.drop(index = test_idx)\n",
    "\n",
    "# train_images, valid_images = train_test_split(images, shuffle = True, random_state = RANDOM_SEED)\n",
    "# train_images = train_images.reset_index(drop = True)\n",
    "# valid_images = valid_images.reset_index(drop = True)\n",
    "\n",
    "train_images = images.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "accepting-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metric(y_binary_true, y_binary_pred, y_reg_true, y_reg_pred):\n",
    "    '''\n",
    "    Competition metric\n",
    "    '''\n",
    "    \n",
    "    roc = roc_auc_score(y_binary_true, y_binary_pred)\n",
    "    mae = mean_absolute_error(y_reg_true, y_reg_pred)\n",
    "    return 1000 * (roc - mae), roc, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "flying-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, images, transform=None, batch_size=32,  shuffle=True, is_classification = True, augment = False):\n",
    "        self.images = images\n",
    "        self.indices = np.arange(len(images))\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.is_classification = is_classification\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in index]\n",
    "    \n",
    "        X, y = self.__get_data(batch)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.index)\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        X = np.zeros((self.batch_size, 150, 150, 3))\n",
    "        y_class = np.zeros((self.batch_size,))\n",
    "        y_energy = np.zeros((self.batch_size))\n",
    "        for i, idx in enumerate(batch):\n",
    "            image=cv2.imread(self.images.iloc[idx, 0])[225:375, 225:375, :]\n",
    "            image = cv2.fastNlMeansDenoisingColored(image, None,3,13,13)\n",
    "            X[i,] = image\n",
    "            \n",
    "            if self.augment:\n",
    "                X[i, ] = Config.train_transform(image=X[i,].astype(np.uint8))['image']\n",
    "            particle_class = self.images.iloc[idx, 1]\n",
    "            particle_energy = self.images.iloc[idx, 2]\n",
    "            y_class[i] = particle_class\n",
    "            y_energy[i] = particle_energy\n",
    "        if self.is_classification:\n",
    "            return X / 255.0, y_class\n",
    "        return X / 255.0, y_energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "available-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = DataGenerator(train_images, batch_size = Config.BATCH_SIZE, is_classification = True, augment = False)\n",
    "valid_datagen = DataGenerator(images_leak, batch_size = Config.BATCH_SIZE, is_classification = True)\n",
    "test_datagen = DataGenerator(test_images, batch_size = 1, is_classification = True, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "aware-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data extract\n",
    "\n",
    "X, y_class = train_datagen.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "inclusive-boundary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9ead8283d0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 17\n",
    "plt.imshow((X[idx] * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-stocks",
   "metadata": {},
   "source": [
    "## Class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "violent-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "import numpy as np\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "resistant-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers as L\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_auc', patience=10)\n",
    "ckpt = keras.callbacks.ModelCheckpoint(OUTPUT_PATH / 'models' / 'cnn_classification_best', save_best_only=True, monitor='val_auc', mode='max')\n",
    "    \n",
    "def create_classification_model(base_model):\n",
    "    x = base_model.output\n",
    "    x = L.GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    #x = L.Dense(512, activation='relu')(x)\n",
    "    x = L.Dense(128, activation='relu')(x)\n",
    "    # and a logistic layer -- let's say we have 200 classes\n",
    "    predictions = L.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(optimizer=tensorflow.keras.optimizers.RMSprop(learning_rate=1e-3), loss='binary_crossentropy', metrics = ['AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "guided-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_classification_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-market",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "30/30 [==============================] - 147s 5s/step - loss: 0.8017 - auc: 0.6397 - val_loss: 0.7711 - val_auc: 0.7508\n",
      "Epoch 2/150\n",
      "30/30 [==============================] - 138s 5s/step - loss: 0.5792 - auc: 0.7639 - val_loss: 0.5726 - val_auc: 0.8367\n",
      "Epoch 3/150\n",
      "30/30 [==============================] - 138s 5s/step - loss: 0.5142 - auc: 0.8092 - val_loss: 0.4824 - val_auc: 0.8280\n",
      "Epoch 4/150\n",
      "27/30 [==========================>...] - ETA: 11s - loss: 0.5291 - auc: 0.7922"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(\n",
    "    train_datagen, \n",
    "    steps_per_epoch = Config.STEPS_PER_EPOCH, \n",
    "    validation_data = valid_datagen, \n",
    "    validation_steps = Config.VALIDATION_STEPS_PER_EPOCH, \n",
    "    epochs = Config.TRAINING_EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks = [earlystop]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "hindu-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(OUTPUT_PATH / 'models' / 'cnn_classification_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "adopted-formula",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 23s 193ms/step - loss: 0.5277 - auc: 0.8357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5276896357536316, 0.8356552720069885]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_datagen, batch_size=64, steps=valid_images.shape[0] // 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "reflected-restaurant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5429 - auc: 0.7917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5429269075393677, 0.7916666269302368]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_datagen, batch_size=1, steps=test_images.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "invalid-trinity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.02620491],\n",
       "       [0.60191727],\n",
       "       [0.02053371],\n",
       "       [0.5163692 ],\n",
       "       [0.13396707],\n",
       "       [0.66857994],\n",
       "       [0.6708336 ],\n",
       "       [0.90023726],\n",
       "       [0.45335543],\n",
       "       [0.7269842 ],\n",
       "       [0.22088017],\n",
       "       [0.63909924]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_generator(test_datagen, steps=test_images.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "rural-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(OUTPUT_PATH / 'models' / 'cnn_classification')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
