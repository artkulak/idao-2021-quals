{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models, utils\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import functional as F\n",
    "from skimage import io, transform\n",
    "from torch.optim import lr_scheduler\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from sklearn.metrics import roc_auc_score, mean_absolute_error\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "INPUT_PATH = Path('../input')\n",
    "TRAIN_PATH = INPUT_PATH / 'idao_dataset' / 'train'\n",
    "PRIVATE_PATH = INPUT_PATH / 'idao_dataset' / 'private_test'\n",
    "PUBLIC_PATH = INPUT_PATH / 'idao_dataset' / 'public_test'\n",
    "\n",
    "RANDOM_SEED = 4444\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper1 = {\n",
    "    1:[1, 0, 0, 0, 0, 0],\n",
    "    3:[0, 1, 0, 0, 0, 0],\n",
    "    6:[0, 0, 1, 0, 0, 0],\n",
    "    10:[0, 0, 0, 1, 0, 0],\n",
    "    20:[0, 0, 0, 0, 1, 0],\n",
    "    30:[0, 0, 0, 0, 0, 1],\n",
    "}\n",
    "\n",
    "mapper2 = {\n",
    "    1:0,\n",
    "    3:1,\n",
    "    6:2,\n",
    "    10:3,\n",
    "    20:4,\n",
    "    30:5,\n",
    "}\n",
    "\n",
    "reverse_mapping = {\n",
    "    0: 1,\n",
    "    1: 3,\n",
    "    2: 6,\n",
    "    3: 10,\n",
    "    4: 20,\n",
    "    5: 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "images = glob.glob(str(TRAIN_PATH / '**/*.png'), recursive=True)\n",
    "\n",
    "train_images, test_images = train_test_split(images, shuffle = True, random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metric(y_binary_true, y_binary_pred, y_reg_true, y_reg_pred):\n",
    "    '''\n",
    "    Competition metric\n",
    "    '''\n",
    "    \n",
    "    roc = roc_auc_score(y_binary_true, y_binary_pred)\n",
    "    mae = mean_absolute_error(y_reg_true, y_reg_pred)\n",
    "    return 1000 * (roc - mae), roc, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGetter(Dataset):\n",
    "    def __init__(self, image_paths, train=True, transform=None):\n",
    " \n",
    "        self.image_paths = image_paths \n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image=cv2.imread(self.image_paths[idx])\n",
    "        if len(self.image_paths[idx].split('_')) == 18:\n",
    "            particle_class = 0\n",
    "            particle_energy = mapper2[int(self.image_paths[idx].split('_')[7])]\n",
    "        else:\n",
    "            particle_class = 1\n",
    "            particle_energy = mapper2[int(self.image_paths[idx].split('_')[8])]\n",
    "        \n",
    "        sample={\n",
    "            'image': np.uint8(image), \n",
    "            'particle_class': particle_class,\n",
    "            'particle_energy': particle_energy\n",
    "            }\n",
    "\n",
    "        #Applying transformation\n",
    "        if self.transform:\n",
    "            sample['image']=self.transform(sample['image'])\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize([128,128]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train_data = DataGetter(train_images, train=True, transform=augs)\n",
    "transformed_test_data = DataGetter(test_images, train=False, transform=augs)\n",
    "\n",
    "train_dataloader = DataLoader(transformed_train_data, batch_size=32, shuffle=True) #, num_workers=2\n",
    "test_dataloader = DataLoader(transformed_test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super(CNN, self).__init__()\n",
    "        if pretrained:\n",
    "            self.model = models.resnet18(pretrained=True)\n",
    "        else:\n",
    "            self.model = models.resnet18()\n",
    "        self.model = nn.Sequential(*list(self.model.children())[:-1])\n",
    "        \n",
    "        self.fc0 = nn.Linear(512, 64)\n",
    "        self.fc1 = nn.Linear(64, 2)  # For classification\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, _, _, _ = x.shape\n",
    "        x = self.model(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        x = self.relu(self.fc0(x))\n",
    "        particle_class = torch.softmax(self.fc1(x), dim = 1)\n",
    "        return {'particle_class': particle_class}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_CNN = CNN(False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'particle_class': tensor([[0.4040, 0.5960],\n",
       "         [0.4580, 0.5420],\n",
       "         [0.4278, 0.5722],\n",
       "         [0.4286, 0.5714],\n",
       "         [0.2901, 0.7099],\n",
       "         [0.4603, 0.5397],\n",
       "         [0.4197, 0.5803],\n",
       "         [0.4545, 0.5455],\n",
       "         [0.4400, 0.5600],\n",
       "         [0.4471, 0.5529],\n",
       "         [0.3924, 0.6076],\n",
       "         [0.4581, 0.5419],\n",
       "         [0.4541, 0.5459],\n",
       "         [0.4577, 0.5423],\n",
       "         [0.4065, 0.5935],\n",
       "         [0.4047, 0.5953],\n",
       "         [0.4482, 0.5518],\n",
       "         [0.4125, 0.5875],\n",
       "         [0.4613, 0.5387],\n",
       "         [0.4008, 0.5992],\n",
       "         [0.3479, 0.6521],\n",
       "         [0.4670, 0.5330],\n",
       "         [0.3692, 0.6308],\n",
       "         [0.4691, 0.5309],\n",
       "         [0.4575, 0.5425],\n",
       "         [0.4541, 0.5459],\n",
       "         [0.4641, 0.5359],\n",
       "         [0.4536, 0.5464],\n",
       "         [0.4570, 0.5430],\n",
       "         [0.4607, 0.5393],\n",
       "         [0.4554, 0.5446],\n",
       "         [0.4503, 0.5497]], device='cuda:0', grad_fn=<SoftmaxBackward>)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for item in train_dataloader:\n",
    "#     img = item['image']\n",
    "#     break\n",
    "# model_CNN(img.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For binary output:particle_class\n",
    "criterion_binary= nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_CNN.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion_binary, optimizer, n_epochs=5):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf\n",
    "    for epoch in range(1, n_epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        comp_metric = 0 \n",
    "        comp_val_metric = 0\n",
    "        batches = 0\n",
    "        val_batches = 0\n",
    "        max_batches = 128\n",
    "        # train the model #\n",
    "        model.train()\n",
    "        for batch_idx, sample_batched in enumerate(train_dataloader):\n",
    "            if batches > max_batches:\n",
    "                break\n",
    "            # importing data and moving to GPU\n",
    "            image, particle_class = sample_batched['image'].to(device),\\\n",
    "                                             sample_batched['particle_class'].to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            output = model(image)\n",
    "            label_class = output['particle_class']\n",
    "    \n",
    "            \n",
    "            particle_class = particle_class.squeeze().type(torch.LongTensor).to(device)\n",
    "            \n",
    "            \n",
    "            y_pred_binary = label_class.cpu().detach().numpy()[:, 1]\n",
    "            y_true_binary = particle_class.cpu().detach().numpy()\n",
    "            \n",
    "            roc = roc_auc_score(y_true_binary, y_pred_binary) \n",
    "\n",
    "            loss_binary = criterion_binary(label_class, particle_class)\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            loss = loss_binary\n",
    "            # back prop\n",
    "            loss.backward()\n",
    "            # grad\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            if batch_idx % 50 == 0:\n",
    "                print('Epoch %d, Batch %d loss: %.6f ROC AUC %.6f' %\n",
    "                  (epoch, batch_idx + 1, train_loss, roc))\n",
    "            batches += 1\n",
    "        # validate the model #\n",
    "        model.eval()\n",
    "        \n",
    "        y_preds = []\n",
    "        y_trues = []\n",
    "        for batch_idx, sample_batched in enumerate(test_dataloader):\n",
    "            if val_batches > max_batches:\n",
    "                break\n",
    "            image, particle_class = sample_batched['image'].to(device),\\\n",
    "                                             sample_batched['particle_class'].to(device)\n",
    "                                              \n",
    "            \n",
    "            output = model(image)\n",
    "\n",
    "            label_class = output['particle_class']\n",
    "\n",
    "            \n",
    "            particle_class = particle_class.squeeze().type(torch.LongTensor).to(device)\n",
    "            \n",
    "            \n",
    "            y_pred_binary = label_class.cpu().detach().numpy()[:, 1]\n",
    "            y_true_binary = particle_class.cpu().detach().numpy()\n",
    "            \n",
    "            y_preds.extend(list(y_pred_binary))\n",
    "            y_trues.extend(list(y_true_binary))\n",
    "            \n",
    "            # calculate loss\n",
    "            loss_binary = criterion_binary(label_class, particle_class)\n",
    "            \n",
    "            loss = loss_binary\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            val_batches += 1\n",
    "        \n",
    "        roc_val = roc_auc_score(y_trues, y_preds) \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t ROC AUC {:.6f}'.format(\n",
    "            epoch, train_loss, valid_loss, roc_val))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            torch.save(model, 'model_classification.pt')\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            valid_loss_min = valid_loss\n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1 loss: 0.545860 ROC AUC 0.855469\n",
      "Epoch 1, Batch 51 loss: 0.378313 ROC AUC 0.995951\n",
      "Epoch 1, Batch 101 loss: 0.352131 ROC AUC 1.000000\n",
      "Epoch: 1 \tTraining Loss: 0.367238 \tValidation Loss: 0.494362 \t ROC AUC 0.800466\n",
      "Validation loss decreased (inf --> 0.494362).  Saving model ...\n",
      "Epoch 2, Batch 1 loss: 0.313505 ROC AUC 1.000000\n",
      "Epoch 2, Batch 51 loss: 0.445201 ROC AUC 1.000000\n",
      "Epoch 2, Batch 101 loss: 0.390955 ROC AUC 1.000000\n",
      "Epoch: 2 \tTraining Loss: 0.378029 \tValidation Loss: 0.813779 \t ROC AUC 0.990208\n",
      "Epoch 3, Batch 1 loss: 0.313365 ROC AUC 1.000000\n",
      "Epoch 3, Batch 51 loss: 0.318851 ROC AUC 1.000000\n",
      "Epoch 3, Batch 101 loss: 0.325147 ROC AUC 0.988095\n",
      "Epoch: 3 \tTraining Loss: 0.326511 \tValidation Loss: 0.315715 \t ROC AUC 0.999895\n",
      "Validation loss decreased (0.494362 --> 0.315715).  Saving model ...\n",
      "Epoch 4, Batch 1 loss: 0.343286 ROC AUC 1.000000\n",
      "Epoch 4, Batch 51 loss: 0.318035 ROC AUC 1.000000\n",
      "Epoch 4, Batch 101 loss: 0.317860 ROC AUC 1.000000\n",
      "Epoch: 4 \tTraining Loss: 0.320329 \tValidation Loss: 0.814245 \t ROC AUC 0.975196\n"
     ]
    }
   ],
   "source": [
    "model_conv=train_model(model_CNN, criterion_binary, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class CNNReg(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super(CNNReg, self).__init__()\n",
    "        if pretrained:\n",
    "            self.model = models.resnet18(pretrained=True)\n",
    "        else:\n",
    "            self.model = models.resnet18()\n",
    "        self.model = nn.Sequential(*list(self.model.children())[:-1])\n",
    "        \n",
    "        self.fc0 = nn.Linear(512, 64)\n",
    "        self.fc1 = nn.Linear(64, 6)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, _, _, _ = x.shape\n",
    "        x = self.model(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        x = self.relu(self.fc0(x))\n",
    "        particle_energy = torch.softmax(self.fc1(x), dim = 1)\n",
    "        return {'particle_energy': particle_energy}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_reg = CNNReg(False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_reg= nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_reg.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'particle_energy': tensor([[0.1652, 0.1572, 0.1495, 0.2723, 0.1280, 0.1278],\n",
       "         [0.1819, 0.1663, 0.1501, 0.2096, 0.1449, 0.1472],\n",
       "         [0.1817, 0.1558, 0.1430, 0.3194, 0.1080, 0.0922],\n",
       "         [0.1837, 0.1542, 0.1498, 0.2376, 0.1365, 0.1381],\n",
       "         [0.1796, 0.1576, 0.1513, 0.2174, 0.1470, 0.1470],\n",
       "         [0.1721, 0.1601, 0.1472, 0.2646, 0.1292, 0.1267],\n",
       "         [0.1798, 0.1521, 0.1483, 0.2667, 0.1262, 0.1269],\n",
       "         [0.1868, 0.1590, 0.1481, 0.2203, 0.1441, 0.1418],\n",
       "         [0.1775, 0.1582, 0.1478, 0.2164, 0.1544, 0.1457],\n",
       "         [0.1842, 0.1527, 0.1450, 0.2217, 0.1475, 0.1489],\n",
       "         [0.1639, 0.1497, 0.1394, 0.3509, 0.0969, 0.0992],\n",
       "         [0.1782, 0.1593, 0.1462, 0.2176, 0.1456, 0.1532],\n",
       "         [0.1858, 0.1560, 0.1490, 0.2631, 0.1253, 0.1208],\n",
       "         [0.1706, 0.1598, 0.1436, 0.2291, 0.1471, 0.1497],\n",
       "         [0.1738, 0.1573, 0.1471, 0.2695, 0.1232, 0.1291],\n",
       "         [0.1801, 0.1608, 0.1486, 0.2120, 0.1513, 0.1471],\n",
       "         [0.1892, 0.1580, 0.1494, 0.2352, 0.1332, 0.1350],\n",
       "         [0.1822, 0.1603, 0.1470, 0.2442, 0.1440, 0.1222],\n",
       "         [0.1813, 0.1567, 0.1462, 0.2448, 0.1343, 0.1368],\n",
       "         [0.1762, 0.1548, 0.1494, 0.2242, 0.1499, 0.1454],\n",
       "         [0.1737, 0.1563, 0.1467, 0.2328, 0.1423, 0.1481],\n",
       "         [0.1768, 0.1592, 0.1451, 0.2652, 0.1280, 0.1258],\n",
       "         [0.1813, 0.1558, 0.1500, 0.2564, 0.1280, 0.1286],\n",
       "         [0.1727, 0.1563, 0.1464, 0.2223, 0.1492, 0.1531],\n",
       "         [0.1726, 0.1610, 0.1455, 0.2254, 0.1482, 0.1473],\n",
       "         [0.1792, 0.1573, 0.1446, 0.2145, 0.1512, 0.1531],\n",
       "         [0.1864, 0.1519, 0.1479, 0.2394, 0.1402, 0.1342],\n",
       "         [0.1841, 0.1573, 0.1500, 0.2125, 0.1511, 0.1450],\n",
       "         [0.1777, 0.1486, 0.1468, 0.2631, 0.1368, 0.1270],\n",
       "         [0.1672, 0.1676, 0.1329, 0.3362, 0.1033, 0.0927],\n",
       "         [0.1806, 0.1604, 0.1471, 0.2188, 0.1487, 0.1444],\n",
       "         [0.1745, 0.1549, 0.1529, 0.2456, 0.1467, 0.1254]], device='cuda:0',\n",
       "        grad_fn=<SoftmaxBackward>)}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in train_dataloader:\n",
    "    img = item['image']\n",
    "    break\n",
    "model_reg(img.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_reg(model, criterion_reg, optimizer, n_epochs=5):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf\n",
    "    for epoch in range(1, n_epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        comp_metric = 0 \n",
    "        comp_val_metric = 0\n",
    "        batches = 0\n",
    "        val_batches = 0\n",
    "        max_batches = 128\n",
    "        # train the model #\n",
    "        model.train()\n",
    "        y_preds = []\n",
    "        y_trues = []\n",
    "        for batch_idx, sample_batched in enumerate(train_dataloader):\n",
    "            if batches > max_batches:\n",
    "                break\n",
    "            # importing data and moving to GPU\n",
    "            image, particle_energy = sample_batched['image'].to(device),\\\n",
    "                                             sample_batched['particle_energy'].to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            output = model(image)\n",
    "            label_energy = output['particle_energy']\n",
    "    \n",
    "            \n",
    "            particle_energy = particle_energy.squeeze().type(torch.LongTensor).to(device)\n",
    "            \n",
    "            \n",
    "            y_pred_reg = label_energy.cpu().detach().numpy()\n",
    "            y_pred_reg = [reverse_mapping[x] for x in list(np.argmax(y_pred_reg, axis = 1))]\n",
    "            \n",
    "            y_true_reg = particle_energy.cpu().detach().numpy()\n",
    "            y_true_reg = [reverse_mapping[x] for x in list(y_true_reg)]\n",
    "            \n",
    "            \n",
    "            mae = mean_absolute_error(y_true_reg, y_pred_reg) \n",
    "\n",
    "            loss_reg = criterion_reg(label_energy, particle_energy)\n",
    "            \n",
    "            y_preds.extend(list(y_pred_reg))\n",
    "            y_trues.extend(list(y_true_reg))\n",
    "            \n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            loss = loss_reg\n",
    "            # back prop\n",
    "            loss.backward()\n",
    "            # grad\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            if batch_idx % 1 == 0:\n",
    "                print('Epoch %d, Batch %d loss: %.6f MAE %.6f' %\n",
    "                  (epoch, batch_idx + 1, train_loss, mae))\n",
    "            batches += 1\n",
    "        # validate the model #\n",
    "        model.eval()\n",
    "        \n",
    "        y_preds = []\n",
    "        y_trues = []\n",
    "        for batch_idx, sample_batched in enumerate(test_dataloader):\n",
    "            if val_batches > max_batches:\n",
    "                break\n",
    "            # importing data and moving to GPU\n",
    "            image, particle_energy = sample_batched['image'].to(device),\\\n",
    "                                             sample_batched['particle_energy'].to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            output = model(image)\n",
    "            label_energy = output['particle_energy']\n",
    "\n",
    "            \n",
    "            particle_energy = particle_energy.squeeze().type(torch.LongTensor).to(device)\n",
    "            \n",
    "            \n",
    "            y_pred_reg = label_energy.cpu().detach().numpy()\n",
    "            y_pred_reg = [reverse_mapping[x] for x in list(np.argmax(y_pred_reg, axis = 1))]\n",
    "            \n",
    "            y_true_reg = particle_energy.cpu().detach().numpy()\n",
    "            y_true_reg = [reverse_mapping[x] for x in list(y_true_reg)]\n",
    "            \n",
    "            y_preds.extend(list(y_pred_reg))\n",
    "            y_trues.extend(list(y_true_reg))\n",
    "            \n",
    "\n",
    "            loss_reg = criterion_reg(label_energy, particle_energy)\n",
    "            \n",
    "            loss = loss_reg\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            val_batches += 1\n",
    "        \n",
    "        mae_val = mean_absolute_error(y_trues, y_preds) \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t MAE {:.6f}'.format(\n",
    "            epoch, train_loss, valid_loss, mae_val))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            torch.save(model, 'model_regression.pt')\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            valid_loss_min = valid_loss\n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1 loss: 1.789550 MAE 7.343750\n",
      "Epoch 1, Batch 2 loss: 1.731750 MAE 3.406250\n",
      "Epoch 1, Batch 3 loss: 1.669055 MAE 2.093750\n",
      "Epoch 1, Batch 4 loss: 1.635806 MAE 2.187500\n",
      "Epoch 1, Batch 5 loss: 1.608848 MAE 2.843750\n",
      "Epoch 1, Batch 6 loss: 1.602455 MAE 3.125000\n",
      "Epoch 1, Batch 7 loss: 1.592353 MAE 3.156250\n",
      "Epoch 1, Batch 8 loss: 1.575077 MAE 2.062500\n",
      "Epoch 1, Batch 9 loss: 1.564806 MAE 2.593750\n",
      "Epoch 1, Batch 10 loss: 1.562843 MAE 3.093750\n",
      "Epoch 1, Batch 11 loss: 1.566602 MAE 3.687500\n",
      "Epoch 1, Batch 12 loss: 1.562003 MAE 2.812500\n",
      "Epoch 1, Batch 13 loss: 1.557052 MAE 2.562500\n",
      "Epoch 1, Batch 14 loss: 1.558689 MAE 3.937500\n",
      "Epoch 1, Batch 15 loss: 1.555058 MAE 2.875000\n",
      "Epoch 1, Batch 16 loss: 1.556695 MAE 3.468750\n",
      "Epoch 1, Batch 17 loss: 1.549032 MAE 2.281250\n",
      "Epoch 1, Batch 18 loss: 1.544991 MAE 2.843750\n",
      "Epoch 1, Batch 19 loss: 1.535101 MAE 1.531250\n",
      "Epoch 1, Batch 20 loss: 1.520038 MAE 0.906250\n",
      "Epoch 1, Batch 21 loss: 1.515708 MAE 3.500000\n",
      "Epoch 1, Batch 22 loss: 1.507476 MAE 1.281250\n",
      "Epoch 1, Batch 23 loss: 1.496115 MAE 0.812500\n",
      "Epoch 1, Batch 24 loss: 1.494016 MAE 3.062500\n",
      "Epoch 1, Batch 25 loss: 1.486960 MAE 1.562500\n",
      "Epoch 1, Batch 26 loss: 1.482423 MAE 0.968750\n",
      "Epoch 1, Batch 27 loss: 1.475622 MAE 2.468750\n",
      "Epoch 1, Batch 28 loss: 1.471754 MAE 0.750000\n",
      "Epoch 1, Batch 29 loss: 1.467488 MAE 1.531250\n",
      "Epoch 1, Batch 30 loss: 1.462110 MAE 0.906250\n",
      "Epoch 1, Batch 31 loss: 1.456401 MAE 1.093750\n",
      "Epoch 1, Batch 32 loss: 1.452766 MAE 1.500000\n",
      "Epoch 1, Batch 33 loss: 1.448867 MAE 1.156250\n",
      "Epoch 1, Batch 34 loss: 1.445720 MAE 1.468750\n",
      "Epoch 1, Batch 35 loss: 1.437446 MAE 0.281250\n",
      "Epoch 1, Batch 36 loss: 1.430042 MAE 0.281250\n",
      "Epoch 1, Batch 37 loss: 1.426484 MAE 1.750000\n",
      "Epoch 1, Batch 38 loss: 1.422286 MAE 0.656250\n",
      "Epoch 1, Batch 39 loss: 1.419324 MAE 1.781250\n",
      "Epoch 1, Batch 40 loss: 1.415225 MAE 0.750000\n",
      "Epoch 1, Batch 41 loss: 1.411259 MAE 1.093750\n",
      "Epoch 1, Batch 42 loss: 1.405015 MAE 0.187500\n",
      "Epoch 1, Batch 43 loss: 1.402625 MAE 1.218750\n",
      "Epoch 1, Batch 44 loss: 1.398642 MAE 0.812500\n",
      "Epoch 1, Batch 45 loss: 1.394733 MAE 0.687500\n",
      "Epoch 1, Batch 46 loss: 1.391078 MAE 0.781250\n",
      "Epoch 1, Batch 47 loss: 1.388131 MAE 0.781250\n",
      "Epoch 1, Batch 48 loss: 1.389392 MAE 3.062500\n",
      "Epoch 1, Batch 49 loss: 1.386362 MAE 0.656250\n",
      "Epoch 1, Batch 50 loss: 1.381565 MAE 0.281250\n",
      "Epoch 1, Batch 51 loss: 1.382993 MAE 2.812500\n",
      "Epoch 1, Batch 52 loss: 1.378690 MAE 0.281250\n",
      "Epoch 1, Batch 53 loss: 1.376616 MAE 0.843750\n",
      "Epoch 1, Batch 54 loss: 1.373366 MAE 0.468750\n",
      "Epoch 1, Batch 55 loss: 1.369752 MAE 0.468750\n",
      "Epoch 1, Batch 56 loss: 1.366947 MAE 0.687500\n",
      "Epoch 1, Batch 57 loss: 1.366316 MAE 2.125000\n",
      "Epoch 1, Batch 58 loss: 1.364821 MAE 1.406250\n",
      "Epoch 1, Batch 59 loss: 1.362115 MAE 0.906250\n",
      "Epoch 1, Batch 60 loss: 1.361863 MAE 1.343750\n",
      "Epoch 1, Batch 61 loss: 1.359258 MAE 0.468750\n",
      "Epoch 1, Batch 62 loss: 1.358541 MAE 1.500000\n",
      "Epoch 1, Batch 63 loss: 1.355935 MAE 0.468750\n",
      "Epoch 1, Batch 64 loss: 1.354647 MAE 0.843750\n",
      "Epoch 1, Batch 65 loss: 1.351452 MAE 0.187500\n",
      "Epoch 1, Batch 66 loss: 1.349664 MAE 0.656250\n",
      "Epoch 1, Batch 67 loss: 1.347941 MAE 0.750000\n",
      "Epoch 1, Batch 68 loss: 1.345894 MAE 0.656250\n",
      "Epoch 1, Batch 69 loss: 1.344177 MAE 0.656250\n",
      "Epoch 1, Batch 70 loss: 1.342103 MAE 0.593750\n",
      "Epoch 1, Batch 71 loss: 1.339317 MAE 0.281250\n",
      "Epoch 1, Batch 72 loss: 1.337390 MAE 0.562500\n",
      "Epoch 1, Batch 73 loss: 1.334697 MAE 0.375000\n",
      "Epoch 1, Batch 74 loss: 1.335922 MAE 3.093750\n",
      "Epoch 1, Batch 75 loss: 1.334257 MAE 0.687500\n",
      "Epoch 1, Batch 76 loss: 1.333469 MAE 0.968750\n",
      "Epoch 1, Batch 77 loss: 1.332527 MAE 0.656250\n",
      "Epoch 1, Batch 78 loss: 1.330381 MAE 0.375000\n",
      "Epoch 1, Batch 79 loss: 1.330931 MAE 1.687500\n",
      "Epoch 1, Batch 80 loss: 1.330182 MAE 0.843750\n",
      "Epoch 1, Batch 81 loss: 1.329733 MAE 0.968750\n",
      "Epoch 1, Batch 82 loss: 1.328655 MAE 0.843750\n",
      "Epoch 1, Batch 83 loss: 1.327298 MAE 0.875000\n",
      "Epoch 1, Batch 84 loss: 1.328584 MAE 2.968750\n",
      "Epoch 1, Batch 85 loss: 1.326538 MAE 0.187500\n",
      "Epoch 1, Batch 86 loss: 1.325214 MAE 0.750000\n",
      "Epoch 1, Batch 87 loss: 1.324353 MAE 0.875000\n",
      "Epoch 1, Batch 88 loss: 1.322326 MAE 0.187500\n",
      "Epoch 1, Batch 89 loss: 1.321100 MAE 0.562500\n",
      "Epoch 1, Batch 90 loss: 1.319475 MAE 0.375000\n",
      "Epoch 1, Batch 91 loss: 1.318654 MAE 0.875000\n",
      "Epoch 1, Batch 92 loss: 1.318153 MAE 0.968750\n",
      "Epoch 1, Batch 93 loss: 1.317388 MAE 0.437500\n",
      "Epoch 1, Batch 94 loss: 1.316348 MAE 0.656250\n",
      "Epoch 1, Batch 95 loss: 1.315436 MAE 0.625000\n",
      "Epoch 1, Batch 96 loss: 1.313751 MAE 0.281250\n",
      "Epoch 1, Batch 97 loss: 1.313124 MAE 0.875000\n",
      "Epoch 1, Batch 98 loss: 1.311928 MAE 0.875000\n",
      "Epoch 1, Batch 99 loss: 1.312073 MAE 0.625000\n",
      "Epoch 1, Batch 100 loss: 1.310844 MAE 0.531250\n",
      "Epoch 1, Batch 101 loss: 1.310009 MAE 0.281250\n",
      "Epoch 1, Batch 102 loss: 1.308764 MAE 0.593750\n",
      "Epoch 1, Batch 103 loss: 1.307852 MAE 0.718750\n",
      "Epoch 1, Batch 104 loss: 1.307895 MAE 1.531250\n",
      "Epoch 1, Batch 105 loss: 1.308167 MAE 2.031250\n",
      "Epoch 1, Batch 106 loss: 1.307430 MAE 1.187500\n",
      "Epoch 1, Batch 107 loss: 1.305745 MAE 0.375000\n",
      "Epoch 1, Batch 108 loss: 1.304462 MAE 0.187500\n",
      "Epoch 1, Batch 109 loss: 1.304035 MAE 0.968750\n",
      "Epoch 1, Batch 110 loss: 1.304041 MAE 1.343750\n",
      "Epoch 1, Batch 111 loss: 1.302276 MAE 0.187500\n",
      "Epoch 1, Batch 112 loss: 1.301243 MAE 0.562500\n",
      "Epoch 1, Batch 113 loss: 1.300100 MAE 0.375000\n",
      "Epoch 1, Batch 114 loss: 1.299002 MAE 0.468750\n",
      "Epoch 1, Batch 115 loss: 1.299042 MAE 1.875000\n",
      "Epoch 1, Batch 116 loss: 1.298165 MAE 0.468750\n",
      "Epoch 1, Batch 117 loss: 1.296674 MAE 0.000000\n",
      "Epoch 1, Batch 118 loss: 1.295394 MAE 0.000000\n",
      "Epoch 1, Batch 119 loss: 1.293765 MAE 0.187500\n",
      "Epoch 1, Batch 120 loss: 1.292271 MAE 0.312500\n",
      "Epoch 1, Batch 121 loss: 1.290505 MAE 0.000000\n",
      "Epoch 1, Batch 122 loss: 1.289320 MAE 0.281250\n",
      "Epoch 1, Batch 123 loss: 1.288207 MAE 0.500000\n",
      "Epoch 1, Batch 124 loss: 1.286781 MAE 0.656250\n",
      "Epoch 1, Batch 125 loss: 1.285284 MAE 0.218750\n",
      "Epoch 1, Batch 126 loss: 1.283629 MAE 0.093750\n",
      "Epoch 1, Batch 127 loss: 1.282099 MAE 0.093750\n",
      "Epoch 1, Batch 128 loss: 1.280417 MAE 0.000000\n",
      "Epoch 1, Batch 129 loss: 1.278599 MAE 0.000000\n",
      "Epoch: 1 \tTraining Loss: 1.278599 \tValidation Loss: 1.864733 \t MAE 18.272456\n",
      "Validation loss decreased (inf --> 1.864733).  Saving model ...\n",
      "Epoch 2, Batch 1 loss: 1.138044 MAE 0.718750\n",
      "Epoch 2, Batch 2 loss: 1.091631 MAE 0.000000\n",
      "Epoch 2, Batch 3 loss: 1.078024 MAE 0.000000\n",
      "Epoch 2, Batch 4 loss: 1.108446 MAE 1.406250\n",
      "Epoch 2, Batch 5 loss: 1.100207 MAE 0.093750\n",
      "Epoch 2, Batch 6 loss: 1.098984 MAE 0.312500\n",
      "Epoch 2, Batch 7 loss: 1.096267 MAE 0.312500\n",
      "Epoch 2, Batch 8 loss: 1.104983 MAE 0.718750\n",
      "Epoch 2, Batch 9 loss: 1.113658 MAE 0.843750\n",
      "Epoch 2, Batch 10 loss: 1.113797 MAE 0.375000\n",
      "Epoch 2, Batch 11 loss: 1.113551 MAE 0.625000\n",
      "Epoch 2, Batch 12 loss: 1.107826 MAE 0.000000\n",
      "Epoch 2, Batch 13 loss: 1.109400 MAE 0.750000\n",
      "Epoch 2, Batch 14 loss: 1.106223 MAE 0.218750\n",
      "Epoch 2, Batch 15 loss: 1.104677 MAE 0.312500\n",
      "Epoch 2, Batch 16 loss: 1.100980 MAE 0.000000\n",
      "Epoch 2, Batch 17 loss: 1.102539 MAE 0.718750\n",
      "Epoch 2, Batch 18 loss: 1.099619 MAE 0.000000\n",
      "Epoch 2, Batch 19 loss: 1.102728 MAE 1.281250\n",
      "Epoch 2, Batch 20 loss: 1.100767 MAE 0.093750\n",
      "Epoch 2, Batch 21 loss: 1.099314 MAE 0.093750\n",
      "Epoch 2, Batch 22 loss: 1.097183 MAE 0.000000\n",
      "Epoch 2, Batch 23 loss: 1.095164 MAE 0.000000\n",
      "Epoch 2, Batch 24 loss: 1.093325 MAE 0.000000\n",
      "Epoch 2, Batch 25 loss: 1.091457 MAE 0.000000\n",
      "Epoch 2, Batch 26 loss: 1.090710 MAE 0.000000\n",
      "Epoch 2, Batch 27 loss: 1.092612 MAE 0.375000\n",
      "Epoch 2, Batch 28 loss: 1.091107 MAE 0.000000\n",
      "Epoch 2, Batch 29 loss: 1.089634 MAE 0.000000\n",
      "Epoch 2, Batch 30 loss: 1.091932 MAE 0.593750\n",
      "Epoch 2, Batch 31 loss: 1.091456 MAE 0.093750\n",
      "Epoch 2, Batch 32 loss: 1.090624 MAE 0.156250\n",
      "Epoch 2, Batch 33 loss: 1.089238 MAE 0.000000\n",
      "Epoch 2, Batch 34 loss: 1.087952 MAE 0.000000\n",
      "Epoch 2, Batch 35 loss: 1.087355 MAE 0.312500\n",
      "Epoch 2, Batch 36 loss: 1.090891 MAE 1.250000\n",
      "Epoch 2, Batch 37 loss: 1.091923 MAE 0.406250\n",
      "Epoch 2, Batch 38 loss: 1.092206 MAE 0.187500\n",
      "Epoch 2, Batch 39 loss: 1.091956 MAE 0.312500\n",
      "Epoch 2, Batch 40 loss: 1.091764 MAE 0.093750\n",
      "Epoch 2, Batch 41 loss: 1.091390 MAE 0.093750\n",
      "Epoch 2, Batch 42 loss: 1.090443 MAE 0.000000\n",
      "Epoch 2, Batch 43 loss: 1.089525 MAE 0.000000\n",
      "Epoch 2, Batch 44 loss: 1.089615 MAE 0.125000\n",
      "Epoch 2, Batch 45 loss: 1.089363 MAE 0.093750\n",
      "Epoch 2, Batch 46 loss: 1.089274 MAE 0.218750\n",
      "Epoch 2, Batch 47 loss: 1.088333 MAE 0.000000\n",
      "Epoch 2, Batch 48 loss: 1.087987 MAE 0.312500\n",
      "Epoch 2, Batch 49 loss: 1.088804 MAE 0.937500\n",
      "Epoch 2, Batch 50 loss: 1.088374 MAE 0.000000\n",
      "Epoch 2, Batch 51 loss: 1.087604 MAE 0.000000\n",
      "Epoch 2, Batch 52 loss: 1.086854 MAE 0.000000\n",
      "Epoch 2, Batch 53 loss: 1.087289 MAE 0.406250\n",
      "Epoch 2, Batch 54 loss: 1.086738 MAE 0.000000\n",
      "Epoch 2, Batch 55 loss: 1.085977 MAE 0.000000\n",
      "Epoch 2, Batch 56 loss: 1.085227 MAE 0.000000\n",
      "Epoch 2, Batch 57 loss: 1.084517 MAE 0.000000\n",
      "Epoch 2, Batch 58 loss: 1.083824 MAE 0.000000\n",
      "Epoch 2, Batch 59 loss: 1.083150 MAE 0.000000\n",
      "Epoch 2, Batch 60 loss: 1.082530 MAE 0.000000\n",
      "Epoch 2, Batch 61 loss: 1.081918 MAE 0.000000\n",
      "Epoch 2, Batch 62 loss: 1.081365 MAE 0.000000\n",
      "Epoch 2, Batch 63 loss: 1.080771 MAE 0.000000\n",
      "Epoch 2, Batch 64 loss: 1.080236 MAE 0.000000\n",
      "Epoch 2, Batch 65 loss: 1.079695 MAE 0.000000\n",
      "Epoch 2, Batch 66 loss: 1.079480 MAE 0.625000\n",
      "Epoch 2, Batch 67 loss: 1.079422 MAE 0.156250\n",
      "Epoch 2, Batch 68 loss: 1.078943 MAE 0.000000\n",
      "Epoch 2, Batch 69 loss: 1.078432 MAE 0.000000\n",
      "Epoch 2, Batch 70 loss: 1.077949 MAE 0.000000\n",
      "Epoch 2, Batch 71 loss: 1.077467 MAE 0.000000\n",
      "Epoch 2, Batch 72 loss: 1.076998 MAE 0.000000\n",
      "Epoch 2, Batch 73 loss: 1.077025 MAE 0.312500\n",
      "Epoch 2, Batch 74 loss: 1.076920 MAE 0.312500\n",
      "Epoch 2, Batch 75 loss: 1.076480 MAE 0.000000\n",
      "Epoch 2, Batch 76 loss: 1.076055 MAE 0.000000\n",
      "Epoch 2, Batch 77 loss: 1.075656 MAE 0.000000\n",
      "Epoch 2, Batch 78 loss: 1.075250 MAE 0.000000\n",
      "Epoch 2, Batch 79 loss: 1.074874 MAE 0.000000\n",
      "Epoch 2, Batch 80 loss: 1.075050 MAE 0.625000\n",
      "Epoch 2, Batch 81 loss: 1.074663 MAE 0.000000\n",
      "Epoch 2, Batch 82 loss: 1.074286 MAE 0.000000\n",
      "Epoch 2, Batch 83 loss: 1.073999 MAE 0.000000\n",
      "Epoch 2, Batch 84 loss: 1.074028 MAE 0.312500\n",
      "Epoch 2, Batch 85 loss: 1.073676 MAE 0.000000\n",
      "Epoch 2, Batch 86 loss: 1.074059 MAE 0.187500\n",
      "Epoch 2, Batch 87 loss: 1.073710 MAE 0.000000\n",
      "Epoch 2, Batch 88 loss: 1.073708 MAE 0.093750\n",
      "Epoch 2, Batch 89 loss: 1.073377 MAE 0.000000\n",
      "Epoch 2, Batch 90 loss: 1.073049 MAE 0.000000\n",
      "Epoch 2, Batch 91 loss: 1.072760 MAE 0.000000\n",
      "Epoch 2, Batch 92 loss: 1.072549 MAE 0.000000\n",
      "Epoch 2, Batch 93 loss: 1.072246 MAE 0.000000\n",
      "Epoch 2, Batch 94 loss: 1.071942 MAE 0.000000\n",
      "Epoch 2, Batch 95 loss: 1.071645 MAE 0.000000\n",
      "Epoch 2, Batch 96 loss: 1.071354 MAE 0.000000\n",
      "Epoch 2, Batch 97 loss: 1.071182 MAE 0.000000\n",
      "Epoch 2, Batch 98 loss: 1.070909 MAE 0.000000\n",
      "Epoch 2, Batch 99 loss: 1.070641 MAE 0.000000\n",
      "Epoch 2, Batch 100 loss: 1.071304 MAE 0.500000\n",
      "Epoch 2, Batch 101 loss: 1.071032 MAE 0.000000\n",
      "Epoch 2, Batch 102 loss: 1.071762 MAE 0.406250\n",
      "Epoch 2, Batch 103 loss: 1.071489 MAE 0.000000\n",
      "Epoch 2, Batch 104 loss: 1.071269 MAE 0.000000\n",
      "Epoch 2, Batch 105 loss: 1.071014 MAE 0.000000\n",
      "Epoch 2, Batch 106 loss: 1.070761 MAE 0.000000\n",
      "Epoch 2, Batch 107 loss: 1.070510 MAE 0.000000\n",
      "Epoch 2, Batch 108 loss: 1.070263 MAE 0.000000\n",
      "Epoch 2, Batch 109 loss: 1.070356 MAE 0.093750\n",
      "Epoch 2, Batch 110 loss: 1.070381 MAE 0.062500\n",
      "Epoch 2, Batch 111 loss: 1.070141 MAE 0.000000\n",
      "Epoch 2, Batch 112 loss: 1.070463 MAE 0.187500\n",
      "Epoch 2, Batch 113 loss: 1.070238 MAE 0.000000\n",
      "Epoch 2, Batch 114 loss: 1.070006 MAE 0.000000\n",
      "Epoch 2, Batch 115 loss: 1.069781 MAE 0.000000\n",
      "Epoch 2, Batch 116 loss: 1.069602 MAE 0.000000\n",
      "Epoch 2, Batch 117 loss: 1.069394 MAE 0.000000\n",
      "Epoch 2, Batch 118 loss: 1.069176 MAE 0.000000\n",
      "Epoch 2, Batch 119 loss: 1.069003 MAE 0.000000\n",
      "Epoch 2, Batch 120 loss: 1.068793 MAE 0.000000\n",
      "Epoch 2, Batch 121 loss: 1.068673 MAE 0.000000\n",
      "Epoch 2, Batch 122 loss: 1.068718 MAE 0.312500\n",
      "Epoch 2, Batch 123 loss: 1.068613 MAE 0.000000\n",
      "Epoch 2, Batch 124 loss: 1.068429 MAE 0.000000\n",
      "Epoch 2, Batch 125 loss: 1.068231 MAE 0.000000\n",
      "Epoch 2, Batch 126 loss: 1.068037 MAE 0.000000\n",
      "Epoch 2, Batch 127 loss: 1.067921 MAE 0.000000\n",
      "Epoch 2, Batch 128 loss: 1.067737 MAE 0.000000\n",
      "Epoch 2, Batch 129 loss: 1.067571 MAE 0.000000\n",
      "Epoch: 2 \tTraining Loss: 1.067571 \tValidation Loss: 1.046857 \t MAE 0.008057\n",
      "Validation loss decreased (1.864733 --> 1.046857).  Saving model ...\n",
      "Epoch 3, Batch 1 loss: 1.045193 MAE 0.000000\n",
      "Epoch 3, Batch 2 loss: 1.044423 MAE 0.000000\n",
      "Epoch 3, Batch 3 loss: 1.045391 MAE 0.000000\n",
      "Epoch 3, Batch 4 loss: 1.049197 MAE 0.093750\n",
      "Epoch 3, Batch 5 loss: 1.048117 MAE 0.000000\n",
      "Epoch 3, Batch 6 loss: 1.048388 MAE 0.000000\n",
      "Epoch 3, Batch 7 loss: 1.048365 MAE 0.000000\n",
      "Epoch 3, Batch 8 loss: 1.048222 MAE 0.000000\n",
      "Epoch 3, Batch 9 loss: 1.047751 MAE 0.000000\n",
      "Epoch 3, Batch 10 loss: 1.049524 MAE 0.093750\n",
      "Epoch 3, Batch 11 loss: 1.049006 MAE 0.000000\n",
      "Epoch 3, Batch 12 loss: 1.050681 MAE 0.218750\n",
      "Epoch 3, Batch 13 loss: 1.050234 MAE 0.000000\n",
      "Epoch 3, Batch 14 loss: 1.049791 MAE 0.000000\n",
      "Epoch 3, Batch 15 loss: 1.049404 MAE 0.000000\n",
      "Epoch 3, Batch 16 loss: 1.049076 MAE 0.000000\n",
      "Epoch 3, Batch 17 loss: 1.048769 MAE 0.000000\n",
      "Epoch 3, Batch 18 loss: 1.049478 MAE 0.218750\n",
      "Epoch 3, Batch 19 loss: 1.049178 MAE 0.000000\n",
      "Epoch 3, Batch 20 loss: 1.049015 MAE 0.000000\n",
      "Epoch 3, Batch 21 loss: 1.048759 MAE 0.000000\n",
      "Epoch 3, Batch 22 loss: 1.049106 MAE 0.000000\n",
      "Epoch 3, Batch 23 loss: 1.048869 MAE 0.000000\n",
      "Epoch 3, Batch 24 loss: 1.048652 MAE 0.000000\n",
      "Epoch 3, Batch 25 loss: 1.048738 MAE 0.000000\n",
      "Epoch 3, Batch 26 loss: 1.049768 MAE 0.093750\n",
      "Epoch 3, Batch 27 loss: 1.049661 MAE 0.000000\n",
      "Epoch 3, Batch 28 loss: 1.049445 MAE 0.000000\n",
      "Epoch 3, Batch 29 loss: 1.049273 MAE 0.000000\n",
      "Epoch 3, Batch 30 loss: 1.049087 MAE 0.000000\n",
      "Epoch 3, Batch 31 loss: 1.048936 MAE 0.000000\n",
      "Epoch 3, Batch 32 loss: 1.048830 MAE 0.000000\n",
      "Epoch 3, Batch 33 loss: 1.050722 MAE 0.187500\n",
      "Epoch 3, Batch 34 loss: 1.051797 MAE 0.218750\n",
      "Epoch 3, Batch 35 loss: 1.051592 MAE 0.000000\n",
      "Epoch 3, Batch 36 loss: 1.051376 MAE 0.000000\n",
      "Epoch 3, Batch 37 loss: 1.052054 MAE 0.312500\n",
      "Epoch 3, Batch 38 loss: 1.051833 MAE 0.000000\n",
      "Epoch 3, Batch 39 loss: 1.051630 MAE 0.000000\n",
      "Epoch 3, Batch 40 loss: 1.051653 MAE 0.000000\n",
      "Epoch 3, Batch 41 loss: 1.051466 MAE 0.000000\n",
      "Epoch 3, Batch 42 loss: 1.052774 MAE 0.437500\n",
      "Epoch 3, Batch 43 loss: 1.052563 MAE 0.000000\n",
      "Epoch 3, Batch 44 loss: 1.052368 MAE 0.000000\n",
      "Epoch 3, Batch 45 loss: 1.054638 MAE 0.750000\n",
      "Epoch 3, Batch 46 loss: 1.054515 MAE 0.000000\n",
      "Epoch 3, Batch 47 loss: 1.055586 MAE 0.312500\n",
      "Epoch 3, Batch 48 loss: 1.055437 MAE 0.000000\n",
      "Epoch 3, Batch 49 loss: 1.055198 MAE 0.000000\n",
      "Epoch 3, Batch 50 loss: 1.055050 MAE 0.000000\n",
      "Epoch 3, Batch 51 loss: 1.054826 MAE 0.000000\n",
      "Epoch 3, Batch 52 loss: 1.054614 MAE 0.000000\n",
      "Epoch 3, Batch 53 loss: 1.054422 MAE 0.000000\n",
      "Epoch 3, Batch 54 loss: 1.054223 MAE 0.000000\n",
      "Epoch 3, Batch 55 loss: 1.054220 MAE 0.000000\n",
      "Epoch 3, Batch 56 loss: 1.054472 MAE 0.093750\n",
      "Epoch 3, Batch 57 loss: 1.054430 MAE 0.000000\n",
      "Epoch 3, Batch 58 loss: 1.054765 MAE 0.093750\n",
      "Epoch 3, Batch 59 loss: 1.055104 MAE 0.093750\n",
      "Epoch 3, Batch 60 loss: 1.054915 MAE 0.000000\n",
      "Epoch 3, Batch 61 loss: 1.054730 MAE 0.000000\n",
      "Epoch 3, Batch 62 loss: 1.054551 MAE 0.000000\n",
      "Epoch 3, Batch 63 loss: 1.054829 MAE 0.093750\n",
      "Epoch 3, Batch 64 loss: 1.054668 MAE 0.000000\n",
      "Epoch 3, Batch 65 loss: 1.054597 MAE 0.000000\n",
      "Epoch 3, Batch 66 loss: 1.054432 MAE 0.000000\n",
      "Epoch 3, Batch 67 loss: 1.054271 MAE 0.000000\n",
      "Epoch 3, Batch 68 loss: 1.054196 MAE 0.000000\n",
      "Epoch 3, Batch 69 loss: 1.054065 MAE 0.000000\n",
      "Epoch 3, Batch 70 loss: 1.053926 MAE 0.000000\n",
      "Epoch 3, Batch 71 loss: 1.053792 MAE 0.000000\n",
      "Epoch 3, Batch 72 loss: 1.053651 MAE 0.000000\n",
      "Epoch 3, Batch 73 loss: 1.053516 MAE 0.000000\n",
      "Epoch 3, Batch 74 loss: 1.053522 MAE 0.000000\n",
      "Epoch 3, Batch 75 loss: 1.053391 MAE 0.000000\n",
      "Epoch 3, Batch 76 loss: 1.053670 MAE 0.093750\n",
      "Epoch 3, Batch 77 loss: 1.053962 MAE 0.093750\n",
      "Epoch 3, Batch 78 loss: 1.053831 MAE 0.000000\n",
      "Epoch 3, Batch 79 loss: 1.053773 MAE 0.000000\n",
      "Epoch 3, Batch 80 loss: 1.053897 MAE 0.093750\n",
      "Epoch 3, Batch 81 loss: 1.053854 MAE 0.000000\n",
      "Epoch 3, Batch 82 loss: 1.053730 MAE 0.000000\n",
      "Epoch 3, Batch 83 loss: 1.054384 MAE 0.156250\n",
      "Epoch 3, Batch 84 loss: 1.054996 MAE 0.187500\n",
      "Epoch 3, Batch 85 loss: 1.054864 MAE 0.000000\n",
      "Epoch 3, Batch 86 loss: 1.055341 MAE 0.156250\n",
      "Epoch 3, Batch 87 loss: 1.055585 MAE 0.093750\n",
      "Epoch 3, Batch 88 loss: 1.055974 MAE 0.125000\n",
      "Epoch 3, Batch 89 loss: 1.056188 MAE 0.062500\n",
      "Epoch 3, Batch 90 loss: 1.056444 MAE 0.062500\n",
      "Epoch 3, Batch 91 loss: 1.056629 MAE 0.156250\n",
      "Epoch 3, Batch 92 loss: 1.056491 MAE 0.000000\n",
      "Epoch 3, Batch 93 loss: 1.056450 MAE 0.000000\n",
      "Epoch 3, Batch 94 loss: 1.056319 MAE 0.000000\n",
      "Epoch 3, Batch 95 loss: 1.056187 MAE 0.000000\n",
      "Epoch 3, Batch 96 loss: 1.056165 MAE 0.000000\n",
      "Epoch 3, Batch 97 loss: 1.056036 MAE 0.000000\n",
      "Epoch 3, Batch 98 loss: 1.055910 MAE 0.000000\n",
      "Epoch 3, Batch 99 loss: 1.055789 MAE 0.000000\n",
      "Epoch 3, Batch 100 loss: 1.055669 MAE 0.000000\n",
      "Epoch 3, Batch 101 loss: 1.055552 MAE 0.000000\n",
      "Epoch 3, Batch 102 loss: 1.055691 MAE 0.093750\n",
      "Epoch 3, Batch 103 loss: 1.055575 MAE 0.000000\n",
      "Epoch 3, Batch 104 loss: 1.055742 MAE 0.093750\n",
      "Epoch 3, Batch 105 loss: 1.055900 MAE 0.093750\n",
      "Epoch 3, Batch 106 loss: 1.056089 MAE 0.312500\n",
      "Epoch 3, Batch 107 loss: 1.056314 MAE 0.062500\n",
      "Epoch 3, Batch 108 loss: 1.056197 MAE 0.000000\n",
      "Epoch 3, Batch 109 loss: 1.056082 MAE 0.000000\n",
      "Epoch 3, Batch 110 loss: 1.055970 MAE 0.000000\n",
      "Epoch 3, Batch 111 loss: 1.056048 MAE 0.312500\n",
      "Epoch 3, Batch 112 loss: 1.056217 MAE 0.093750\n",
      "Epoch 3, Batch 113 loss: 1.056121 MAE 0.000000\n",
      "Epoch 3, Batch 114 loss: 1.057882 MAE 2.187500\n",
      "Epoch 3, Batch 115 loss: 1.059060 MAE 0.687500\n",
      "Epoch 3, Batch 116 loss: 1.058927 MAE 0.000000\n",
      "Epoch 3, Batch 117 loss: 1.058797 MAE 0.000000\n",
      "Epoch 3, Batch 118 loss: 1.058669 MAE 0.000000\n",
      "Epoch 3, Batch 119 loss: 1.058761 MAE 0.093750\n",
      "Epoch 3, Batch 120 loss: 1.058990 MAE 0.937500\n",
      "Epoch 3, Batch 121 loss: 1.058922 MAE 0.000000\n",
      "Epoch 3, Batch 122 loss: 1.059258 MAE 0.625000\n",
      "Epoch 3, Batch 123 loss: 1.059132 MAE 0.000000\n",
      "Epoch 3, Batch 124 loss: 1.059245 MAE 0.062500\n",
      "Epoch 3, Batch 125 loss: 1.059176 MAE 0.000000\n",
      "Epoch 3, Batch 126 loss: 1.059387 MAE 0.093750\n",
      "Epoch 3, Batch 127 loss: 1.059319 MAE 0.000000\n",
      "Epoch 3, Batch 128 loss: 1.059672 MAE 0.625000\n",
      "Epoch 3, Batch 129 loss: 1.059555 MAE 0.000000\n"
     ]
    }
   ],
   "source": [
    "model_reg = train_model_reg(model_reg, criterion_reg, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pt')\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataGetter(Dataset):\n",
    "    def __init__(self, image_paths, train=True, transform=None):\n",
    " \n",
    "        self.image_paths = image_paths \n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image=cv2.imread(self.image_paths[idx])\n",
    "        \n",
    "        sample={\n",
    "            'image': np.uint8(image)\n",
    "            }\n",
    "\n",
    "        #Applying transformation\n",
    "        if self.transform:\n",
    "            sample['image']=self.transform(sample['image'])\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_test = glob.glob(str(PRIVATE_PATH / '**/*.png'), recursive=True)\n",
    "public_test = glob.glob(str(PUBLIC_PATH / '**/*.png'), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_test_getter = TestDataGetter(private_test, transform=augs)\n",
    "public_test_getter = TestDataGetter(public_test, transform=augs)\n",
    "\n",
    "private_test_dataloader = DataLoader(private_test_getter, batch_size=32, shuffle=False) #, num_workers=2\n",
    "public_test_dataloader = DataLoader(public_test_getter, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    753\n",
       "0    749\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# public set\n",
    "\n",
    "public_predictions = []\n",
    "for batch in public_test_dataloader:\n",
    "    imgs = batch['image'].to(device)\n",
    "    preds = model(imgs)\n",
    "    preds = preds['particle_class'].cpu().detach().numpy()\n",
    "    preds = np.argmax(preds, axis = 1)\n",
    "    \n",
    "    public_predictions.extend(preds)\n",
    "pd.Series(public_predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-c3a228adb8ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprivate_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprivate_test_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-ff44b226d7af>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         sample={\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# private set\n",
    "\n",
    "private_predictions = []\n",
    "for batch in private_test_dataloader:\n",
    "    imgs = batch['image'].to(device)\n",
    "    preds = model(imgs)\n",
    "    preds = preds['particle_class'].cpu().detach().numpy()\n",
    "    preds = np.argmax(preds, axis = 1)\n",
    "    \n",
    "    private_predictions.extend(preds)\n",
    "pd.Series(private_predictions).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
