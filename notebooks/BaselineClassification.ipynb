{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models, utils\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import functional as F\n",
    "from skimage import io, transform\n",
    "from torch.optim import lr_scheduler\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from sklearn.metrics import roc_auc_score, mean_absolute_error\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "INPUT_PATH = Path('../input')\n",
    "TRAIN_PATH = INPUT_PATH / 'idao_dataset' / 'train'\n",
    "PRIVATE_PATH = INPUT_PATH / 'idao_dataset' / 'private_test'\n",
    "PUBLIC_PATH = INPUT_PATH / 'idao_dataset' / 'private_test'\n",
    "\n",
    "RANDOM_SEED = 4444\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "images = glob.glob(str(TRAIN_PATH / '**/*.png'), recursive=True)\n",
    "\n",
    "train_images, test_images = train_test_split(images, shuffle = True, random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metric(y_binary_true, y_binary_pred, y_reg_true, y_reg_pred):\n",
    "    '''\n",
    "    Competition metric\n",
    "    '''\n",
    "    \n",
    "    roc = roc_auc_score(y_binary_true, y_binary_pred)\n",
    "    mae = mean_absolute_error(y_reg_true, y_reg_pred)\n",
    "    return 1000 * (roc - mae), roc, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper1 = {\n",
    "    1:[1, 0, 0, 0, 0, 0],\n",
    "    3:[0, 1, 0, 0, 0, 0],\n",
    "    6:[0, 0, 1, 0, 0, 0],\n",
    "    10:[0, 0, 0, 1, 0, 0],\n",
    "    20:[0, 0, 0, 0, 1, 0],\n",
    "    30:[0, 0, 0, 0, 0, 1],\n",
    "}\n",
    "\n",
    "mapper2 = {\n",
    "    1:0,\n",
    "    3:1,\n",
    "    6:2,\n",
    "    10:3,\n",
    "    20:4,\n",
    "    30:5,\n",
    "}\n",
    "\n",
    "reverse_mapping = {\n",
    "    0: 1,\n",
    "    1: 3,\n",
    "    2: 6,\n",
    "    3: 10,\n",
    "    4: 20,\n",
    "    5: 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGetter(Dataset):\n",
    "    def __init__(self, image_paths, train=True, transform=None):\n",
    " \n",
    "        self.image_paths = image_paths \n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image=cv2.imread(self.image_paths[idx])\n",
    "        if len(self.image_paths[idx].split('_')) == 18:\n",
    "            particle_class = 1\n",
    "            particle_energy = mapper2[int(self.image_paths[idx].split('_')[7])]\n",
    "        else:\n",
    "            particle_class = 0\n",
    "            particle_energy = mapper2[int(self.image_paths[idx].split('_')[8])]\n",
    "\n",
    "        sample={\n",
    "            'image': np.uint8(image), \n",
    "            'particle_class': particle_class,\n",
    "            'particle_energy': particle_energy\n",
    "            }\n",
    "\n",
    "        #Applying transformation\n",
    "        if self.transform:\n",
    "            sample['image']=self.transform(sample['image'])\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize([128,128]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train_data = DataGetter(train_images, train=True, transform=augs)\n",
    "transformed_test_data = DataGetter(test_images, train=False, transform=augs)\n",
    "\n",
    "train_dataloader = DataLoader(transformed_train_data, batch_size=32, shuffle=True) #, num_workers=2\n",
    "test_dataloader = DataLoader(transformed_test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super(CNN, self).__init__()\n",
    "        if pretrained:\n",
    "            self.model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        else:\n",
    "            self.model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        \n",
    "        self.fc0 = nn.Linear(1280, 64)\n",
    "        self.fc1 = nn.Linear(64, 2)  # For classification\n",
    "        self.fc2 = nn.Linear(64, 6)  # For another classification\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs, _, _, _ = x.shape\n",
    "        x = self.model.extract_features(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        x = self.fc0(x)\n",
    "        particle_class = torch.softmax(self.fc1(x), dim = 1)\n",
    "        particle_energy= torch.softmax(self.fc2(x), dim = 1)\n",
    "        return {'particle_class': particle_class, 'particle_energy': particle_energy}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_CNN = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in train_dataloader:\n",
    "    out = model_CNN(d['image'].to(device))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For binary output:particle_class\n",
    "criterion_binary= nn.CrossEntropyLoss()\n",
    "# For regression output:particle_energy\n",
    "criterion_reg = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_CNN.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion_binary, criterion_reg, optimizer, n_epochs=25):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf\n",
    "    for epoch in range(1, n_epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        comp_metric = 0 \n",
    "        comp_val_metric = 0\n",
    "        # train the model #\n",
    "        model.train()\n",
    "        for batch_idx, sample_batched in enumerate(train_dataloader):\n",
    "            # importing data and moving to GPU\n",
    "            \n",
    "\n",
    "            image, particle_class, particle_energy = sample_batched['image'].to(device),\\\n",
    "                                             sample_batched['particle_class'].to(device),\\\n",
    "                                              sample_batched['particle_energy'].to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            output = model(image)\n",
    "            label_class = output['particle_class']\n",
    "            label_energy = output['particle_energy']\n",
    "            \n",
    "            # calculate loss\n",
    "            particle_class = particle_class.squeeze().type(torch.LongTensor).to(device)\n",
    "            particle_energy = particle_energy.squeeze().type(torch.LongTensor).to(device)\n",
    "            \n",
    "            print(particle_class, particle_energy)\n",
    "            \n",
    "            \n",
    "            y_pred_binary = label_class.cpu().detach().numpy()[:, 1]\n",
    "            y_true_binary = particle_class.cpu().detach().numpy()\n",
    "            y_pred_reg = label_energy.cpu().detach().numpy()\n",
    "            y_true_reg = particle_energy.cpu().detach().numpy()\n",
    "            \n",
    "            y_pred_reg = [reverse_mapping[x] for x in list(np.argmax(y_pred_reg, axis = 1))]\n",
    "            y_true_reg = [reverse_mapping[x] for x in list(y_true_reg)]\n",
    "            comp_metric, roc, mae = calc_metric(y_true_binary, y_pred_binary, y_true_reg, y_pred_reg)\n",
    "            \n",
    "            loss_binary = criterion_binary(label_class, particle_class)\n",
    "            loss_reg = criterion_reg(label_energy, particle_energy)\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            loss = loss_binary + loss_reg\n",
    "            # back prop\n",
    "            loss.backward()\n",
    "            # grad\n",
    "            optimizer.step()\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            if batch_idx % 1 == 0:\n",
    "                print('Epoch %d, Batch %d loss: %.6f Metric %.6f ROC AUC %.6f MAE %.6f' %\n",
    "                  (epoch, batch_idx + 1, train_loss, comp_metric, roc, mae))\n",
    "        # validate the model #\n",
    "        model.eval()\n",
    "        for batch_idx, sample_batched in enumerate(test_dataloader):\n",
    "            image, particle_class, particle_energy = sample_batched['image'].to(device),\\\n",
    "                                             sample_batched['particle_class'].to(device),\\\n",
    "                                              sample_batched['particle_energy'].to(device)\n",
    "            \n",
    "            output = model(image)\n",
    "\n",
    "            label_class = output['particle_class']\n",
    "            label_energy = output['particle_energy']\n",
    "            \n",
    "            particle_class = particle_class.squeeze().type(torch.FloatTensor).to(device)\n",
    "            particle_energy = particle_energy.squeeze().type(torch.FloatTensor).to(device)\n",
    "            \n",
    "            \n",
    "            y_pred_binary = label_class.cpu().detach().numpy()[:, 1]\n",
    "            y_true_binary = particle_class.cpu().detach().numpy()\n",
    "            y_pred_reg = label_energy.cpu().detach().numpy()\n",
    "            y_true_reg = particle_energy.cpu().detach().numpy()\n",
    "            \n",
    "            y_pred_reg = [reverse_mapping[x] for x in list(np.argmax(y_pred_reg, axis = 1))]\n",
    "            y_true_reg = [reverse_mapping[x] for x in list(y_true_reg)]\n",
    "            comp_val_metric, roc_val, mae_val = calc_metric(y_true_binary, y_pred_binary, y_true_reg, y_pred_reg)\n",
    "            \n",
    "            \n",
    "            # calculate loss\n",
    "            loss_binary = criterion_binary(label_class, particle_class)\n",
    "            loss_reg = criterion_reg(label_energy, particle_energy)\n",
    "            \n",
    "            loss = loss_binary + loss_reg\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "        \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tMetric: {:.6f} ROC AUC {:.6f} MAE {:.6f}'.format(\n",
    "            epoch, train_loss, valid_loss, comp_val_metric, roc_val, mae_val))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            torch.save(model, 'model.pt')\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            valid_loss_min = valid_loss\n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 1, 0], device='cuda:0') tensor([3, 2, 2, 3, 1, 1, 4, 5, 2, 1, 3, 2, 4, 5, 0, 5, 0, 4, 2, 1, 5, 3, 5, 5,\n",
      "        5, 3, 2, 0, 4, 3, 1, 0], device='cuda:0')\n",
      "Epoch 1, Batch 1 loss: 2.638103 Metric -16091.911765 ROC AUC 0.470588 MAE 16.562500\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1], device='cuda:0') tensor([5, 3, 0, 3, 4, 2, 4, 2, 1, 2, 3, 3, 1, 4, 1, 5, 3, 5, 1, 1, 3, 0, 5, 3,\n",
      "        4, 0, 1, 1, 2, 2, 0, 3], device='cuda:0')\n",
      "Epoch 1, Batch 2 loss: 2.606853 Metric -18086.538462 ROC AUC 0.538462 MAE 18.625000\n",
      "tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1], device='cuda:0') tensor([4, 3, 5, 1, 2, 3, 3, 3, 3, 5, 0, 4, 0, 1, 2, 1, 2, 3, 4, 4, 5, 4, 0, 0,\n",
      "        4, 1, 2, 1, 2, 3, 5, 5], device='cuda:0')\n",
      "Epoch 1, Batch 3 loss: 2.669353 Metric -16431.985294 ROC AUC 0.411765 MAE 16.843750\n",
      "tensor([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1], device='cuda:0') tensor([2, 3, 5, 4, 1, 5, 3, 0, 4, 1, 2, 3, 0, 5, 1, 1, 1, 1, 0, 4, 4, 5, 2, 3,\n",
      "        1, 3, 2, 5, 3, 2, 1, 3], device='cuda:0')\n",
      "Epoch 1, Batch 4 loss: 2.661541 Metric -16043.750000 ROC AUC 0.425000 MAE 16.468750\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0') tensor([4, 2, 0, 3, 4, 3, 1, 3, 4, 2, 4, 3, 3, 1, 5, 4, 5, 2, 3, 3, 4, 1, 2, 0,\n",
      "        4, 2, 0, 5, 3, 2, 4, 0], device='cuda:0')\n",
      "Epoch 1, Batch 5 loss: 2.700603 Metric -16566.964286 ROC AUC 0.464286 MAE 17.031250\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1], device='cuda:0') tensor([3, 1, 1, 5, 1, 0, 1, 2, 1, 5, 3, 2, 1, 4, 2, 5, 5, 3, 5, 0, 5, 1, 1, 2,\n",
      "        1, 0, 3, 0, 0, 4, 1, 3], device='cuda:0')\n",
      "Epoch 1, Batch 6 loss: 2.684978 Metric -19391.369048 ROC AUC 0.452381 MAE 19.843750\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0], device='cuda:0') tensor([4, 0, 0, 2, 0, 1, 0, 3, 0, 1, 2, 4, 0, 0, 3, 1, 2, 4, 0, 2, 4, 0, 1, 5,\n",
      "        4, 2, 1, 2, 5, 0, 3, 2], device='cuda:0')\n",
      "Epoch 1, Batch 7 loss: 2.722924 Metric -19746.022727 ROC AUC 0.472727 MAE 20.218750\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0') tensor([1, 5, 5, 3, 3, 4, 0, 0, 5, 4, 5, 0, 2, 4, 2, 5, 3, 4, 2, 3, 5, 1, 5, 5,\n",
      "        3, 0, 4, 0, 2, 0, 4, 2], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-b00f1e259477>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_conv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-152-e3758366c0b6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion_binary, criterion_reg, optimizer, n_epochs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_binary\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_reg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# back prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;31m# grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_conv=train_model(model_CNN, criterion_binary, criterion_reg, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
