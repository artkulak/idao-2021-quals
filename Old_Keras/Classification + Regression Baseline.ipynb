{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beautiful-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# IMPORT LIBS\n",
    "#####################\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import io, transform\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from sklearn.metrics import roc_auc_score, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import albumentations as A\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "\n",
    "#####################\n",
    "# SET CONSTANTS\n",
    "#####################\n",
    "\n",
    "INPUT_PATH = Path('../input')\n",
    "OUTPUT_PATH = Path('../output')\n",
    "TRAIN_PATH = INPUT_PATH / 'idao_dataset' / 'train'\n",
    "PRIVATE_PATH = INPUT_PATH / 'idao_dataset' / 'private_test'\n",
    "PUBLIC_PATH = INPUT_PATH / 'idao_dataset' / 'public_test'\n",
    "\n",
    "RANDOM_SEED = 4444\n",
    "\n",
    "ENERGY2CLASS = {\n",
    "    1: [1, 0, 0, 0, 0, 0],\n",
    "    3: [0, 1, 0, 0, 0, 0],\n",
    "    6: [0, 0, 1, 0, 0, 0],\n",
    "    10: [0, 0, 0, 1, 0, 0],\n",
    "    20: [0, 0, 0, 0, 1, 0],\n",
    "    30: [0, 0, 0, 0, 0, 1]\n",
    "    \n",
    "}\n",
    "\n",
    "CLASS2ENERGY = {\n",
    "    0: 1,\n",
    "    1: 3,\n",
    "    2: 6,\n",
    "    3: 10,\n",
    "    4: 20,\n",
    "    5: 30\n",
    "}\n",
    "\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "referenced-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    BATCH_SIZE = 32\n",
    "    TRAINING_EPOCHS = 150\n",
    "    VALIDATION_STEPS_PER_EPOCH = 5\n",
    "    VALIDATION_EPOCHS = 10\n",
    "    STEPS_PER_EPOCH = 30\n",
    "    EARLY_STOP_PATIENCE = 5\n",
    "    \n",
    "    \n",
    "    # Declare an augmentation pipeline\n",
    "    train_transform = A.Compose([\n",
    "        #A.HorizontalFlip(p=0.5),\n",
    "        A.Cutout(num_holes=4, max_h_size=8, max_w_size=8, p=0.3),\n",
    "        A.OneOf([A.RandomContrast(),\n",
    "             A.RandomGamma(),\n",
    "             A.RandomBrightness()],p=0.2),\n",
    "        A.OneOf([A.Blur(p = 0.3),\n",
    "             A.GaussNoise(p=0.3)\n",
    "                ],p=0.5),\n",
    "        A.CLAHE(clip_limit=4, tile_grid_size=(8,8), always_apply=False, p=0.3),\n",
    "    ],)\n",
    "    \n",
    "    validation_transform = A.Compose([\n",
    "    ],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "minus-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(img_path):\n",
    "    if len(img_path.split('_')) == 18:\n",
    "        particle_class = 0 # ER\n",
    "        particle_energy = int(img_path.split('_')[7])\n",
    "    else:\n",
    "        particle_class = 1 # HE\n",
    "        particle_energy = int(img_path.split('_')[8])\n",
    "    return [img_path, particle_class, particle_energy]\n",
    "\n",
    "images = glob.glob(str(TRAIN_PATH / '**/*.png'), recursive=True)\n",
    "images = pd.DataFrame(map(getFeatures, images))\n",
    "images.columns = ['path', 'class', 'energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "following-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# EXTRACT TEST\n",
    "#################\n",
    "\n",
    "# HE - 0, ER - 1\n",
    "\n",
    "he_test_idx = list(images[(images['class'] == 0) & (images['energy'].apply(lambda x: x in [1, 6, 20]))].index)\n",
    "er_test_idx = list(images[(images['class'] == 1) & (images['energy'].apply(lambda x: x in [3, 10, 30]))].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "industrial-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = he_test_idx + er_test_idx\n",
    "test_images = images.iloc[test_idx]\n",
    "images = images.drop(index = test_idx)\n",
    "\n",
    "train_images, valid_images = train_test_split(images, shuffle = True, random_state = RANDOM_SEED)\n",
    "train_images = train_images.reset_index(drop = True)\n",
    "valid_images = valid_images.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inner-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metric(y_binary_true, y_binary_pred, y_reg_true, y_reg_pred):\n",
    "    '''\n",
    "    Competition metric\n",
    "    '''\n",
    "    \n",
    "    roc = roc_auc_score(y_binary_true, y_binary_pred)\n",
    "    mae = mean_absolute_error(y_reg_true, y_reg_pred)\n",
    "    return 1000 * (roc - mae), roc, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "minute-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, images, transform=None, batch_size=32,  shuffle=True, is_classification = True, augment = False):\n",
    "        self.images = images\n",
    "        self.indices = np.arange(len(images))\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.is_classification = is_classification\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in index]\n",
    "    \n",
    "        X, y = self.__get_data(batch)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.index)\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        X = np.zeros((self.batch_size, 150, 150, 3))\n",
    "        y_class = np.zeros((self.batch_size,))\n",
    "        y_energy = np.zeros((self.batch_size))\n",
    "        for i, idx in enumerate(batch):\n",
    "            image=cv2.imread(self.images.iloc[idx, 0])[225:375, 225:375, :]\n",
    "            X[i,] = image\n",
    "            \n",
    "            if self.augment:\n",
    "                X[i, ] = Config.train_transform(image=X[i,].astype(np.uint8))['image']\n",
    "            particle_class = self.images.iloc[idx, 1]\n",
    "            particle_energy = self.images.iloc[idx, 2]\n",
    "            y_class[i] = particle_class\n",
    "            y_energy[i] = particle_energy\n",
    "        if self.is_classification:\n",
    "            return X / 255.0, y_class\n",
    "        return X / 255.0, y_energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "black-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = DataGenerator(train_images, batch_size = Config.BATCH_SIZE, is_classification = True, augment = False)\n",
    "valid_datagen = DataGenerator(valid_images, batch_size = Config.BATCH_SIZE, is_classification = True)\n",
    "test_datagen = DataGenerator(test_images, batch_size = 1, is_classification = True, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "registered-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data extract\n",
    "\n",
    "X, y_class = train_datagen.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-manufacturer",
   "metadata": {},
   "source": [
    "## Class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "requested-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "import numpy as np\n",
    "\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "solved-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers as L\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    \n",
    "def create_classification_model(base_model):\n",
    "    x = base_model.output\n",
    "    x = L.GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    #x = L.Dense(512, activation='relu')(x)\n",
    "    x = L.Dense(128, activation='relu')(x)\n",
    "    # and a logistic layer -- let's say we have 200 classes\n",
    "    predictions = L.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(optimizer=tensorflow.keras.optimizers.RMSprop(learning_rate=1e-3), loss='binary_crossentropy', metrics = ['AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "hydraulic-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_classification_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "olive-martial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.1381 - auc: 0.9889 - val_loss: 1.8235 - val_auc: 0.6667\n",
      "Epoch 2/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1273 - auc: 0.9909 - val_loss: 1.8912 - val_auc: 0.6667\n",
      "Epoch 3/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1446 - auc: 0.9869 - val_loss: 1.8616 - val_auc: 0.6389\n",
      "Epoch 4/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1580 - auc: 0.9846 - val_loss: 1.7540 - val_auc: 0.6389\n",
      "Epoch 5/150\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.1118 - auc: 0.9928 - val_loss: 1.7508 - val_auc: 0.6944\n",
      "Epoch 6/150\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.1405 - auc: 0.9878 - val_loss: 1.8105 - val_auc: 0.7361\n",
      "Epoch 7/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1168 - auc: 0.9915 - val_loss: 1.8146 - val_auc: 0.6528\n",
      "Epoch 8/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.1363 - auc: 0.9880 - val_loss: 1.8031 - val_auc: 0.7222\n",
      "Epoch 9/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1053 - auc: 0.9923 - val_loss: 1.9124 - val_auc: 0.7222\n",
      "Epoch 10/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1110 - auc: 0.9921 - val_loss: 1.8158 - val_auc: 0.6944\n",
      "Epoch 11/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1229 - auc: 0.9911 - val_loss: 1.7895 - val_auc: 0.6667\n",
      "Epoch 12/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0976 - auc: 0.9935 - val_loss: 1.9409 - val_auc: 0.6667\n",
      "Epoch 13/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.1003 - auc: 0.9936 - val_loss: 1.9586 - val_auc: 0.6389\n",
      "Epoch 14/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1445 - auc: 0.9871 - val_loss: 1.7024 - val_auc: 0.6667\n",
      "Epoch 15/150\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.0927 - auc: 0.9944 - val_loss: 1.9440 - val_auc: 0.7222\n",
      "Epoch 16/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1123 - auc: 0.9918 - val_loss: 1.8695 - val_auc: 0.7222\n",
      "Epoch 17/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1207 - auc: 0.9907 - val_loss: 1.7887 - val_auc: 0.6944\n",
      "Epoch 18/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1181 - auc: 0.9907 - val_loss: 1.7614 - val_auc: 0.7222\n",
      "Epoch 19/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1069 - auc: 0.9930 - val_loss: 1.8237 - val_auc: 0.7222\n",
      "Epoch 20/150\n",
      "30/30 [==============================] - 6s 203ms/step - loss: 0.0890 - auc: 0.9951 - val_loss: 1.9692 - val_auc: 0.6667\n",
      "Epoch 21/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.1280 - auc: 0.9899 - val_loss: 1.7318 - val_auc: 0.6667\n",
      "Epoch 22/150\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.1102 - auc: 0.9915 - val_loss: 1.6577 - val_auc: 0.7222\n",
      "Epoch 23/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.0867 - auc: 0.9956 - val_loss: 1.7893 - val_auc: 0.7222\n",
      "Epoch 24/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.1262 - auc: 0.9896 - val_loss: 1.7004 - val_auc: 0.7222\n",
      "Epoch 25/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0971 - auc: 0.9941 - val_loss: 1.7016 - val_auc: 0.7222\n",
      "Epoch 26/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.0776 - auc: 0.9962 - val_loss: 1.8121 - val_auc: 0.6944\n",
      "Epoch 27/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.1010 - auc: 0.9940 - val_loss: 1.7842 - val_auc: 0.6667\n",
      "Epoch 28/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.1219 - auc: 0.9907 - val_loss: 1.7495 - val_auc: 0.7222\n",
      "Epoch 29/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.1023 - auc: 0.9933 - val_loss: 1.7133 - val_auc: 0.7222\n",
      "Epoch 30/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0731 - auc: 0.9962 - val_loss: 2.0085 - val_auc: 0.7222\n",
      "Epoch 31/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.0967 - auc: 0.9942 - val_loss: 1.9761 - val_auc: 0.6667\n",
      "Epoch 32/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.0856 - auc: 0.9952 - val_loss: 1.7800 - val_auc: 0.6389\n",
      "Epoch 33/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0751 - auc: 0.9968 - val_loss: 1.7874 - val_auc: 0.7222\n",
      "Epoch 34/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.1060 - auc: 0.9933 - val_loss: 1.8146 - val_auc: 0.7222\n",
      "Epoch 35/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.1006 - auc: 0.9938 - val_loss: 1.7373 - val_auc: 0.6806\n",
      "Epoch 36/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.0890 - auc: 0.9949 - val_loss: 1.5967 - val_auc: 0.6667\n",
      "Epoch 37/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0848 - auc: 0.9951 - val_loss: 1.8423 - val_auc: 0.6667\n",
      "Epoch 38/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0810 - auc: 0.9956 - val_loss: 1.8682 - val_auc: 0.6667\n",
      "Epoch 39/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0824 - auc: 0.9954 - val_loss: 1.9099 - val_auc: 0.7222\n",
      "Epoch 40/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0908 - auc: 0.9951 - val_loss: 1.6400 - val_auc: 0.6806\n",
      "Epoch 41/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.1064 - auc: 0.9929 - val_loss: 1.4715 - val_auc: 0.6944\n",
      "Epoch 42/150\n",
      "30/30 [==============================] - 6s 207ms/step - loss: 0.0834 - auc: 0.9956 - val_loss: 1.6697 - val_auc: 0.7222\n",
      "Epoch 43/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.0939 - auc: 0.9944 - val_loss: 1.7590 - val_auc: 0.7222\n",
      "Epoch 44/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.0677 - auc: 0.9963 - val_loss: 1.7655 - val_auc: 0.6806\n",
      "Epoch 45/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0800 - auc: 0.9959 - val_loss: 1.7793 - val_auc: 0.7222\n",
      "Epoch 46/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.0859 - auc: 0.9940 - val_loss: 1.7921 - val_auc: 0.6250\n",
      "Epoch 47/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.0811 - auc: 0.9954 - val_loss: 1.6929 - val_auc: 0.7222\n",
      "Epoch 48/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.1072 - auc: 0.9925 - val_loss: 1.5974 - val_auc: 0.6944\n",
      "Epoch 49/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.0815 - auc: 0.9957 - val_loss: 1.7733 - val_auc: 0.6667\n",
      "Epoch 50/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.1051 - auc: 0.9924 - val_loss: 1.7094 - val_auc: 0.6667\n",
      "Epoch 51/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.0920 - auc: 0.9945 - val_loss: 1.7318 - val_auc: 0.7222\n",
      "Epoch 52/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.0883 - auc: 0.9945 - val_loss: 1.4173 - val_auc: 0.7361\n",
      "Epoch 53/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0733 - auc: 0.9968 - val_loss: 1.8853 - val_auc: 0.7222\n",
      "Epoch 54/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0918 - auc: 0.9944 - val_loss: 1.6704 - val_auc: 0.6944\n",
      "Epoch 55/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.0802 - auc: 0.9954 - val_loss: 1.9534 - val_auc: 0.6667\n",
      "Epoch 56/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.1112 - auc: 0.9923 - val_loss: 1.7838 - val_auc: 0.7222\n",
      "Epoch 57/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0967 - auc: 0.9943 - val_loss: 1.4608 - val_auc: 0.6944\n",
      "Epoch 58/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.0912 - auc: 0.9952 - val_loss: 1.5624 - val_auc: 0.6667\n",
      "Epoch 59/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0588 - auc: 0.9982 - val_loss: 1.7430 - val_auc: 0.7222\n",
      "Epoch 60/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0692 - auc: 0.9966 - val_loss: 1.6599 - val_auc: 0.6944\n",
      "Epoch 61/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0811 - auc: 0.9947 - val_loss: 1.9909 - val_auc: 0.6667\n",
      "Epoch 62/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.0922 - auc: 0.9943 - val_loss: 1.8440 - val_auc: 0.6806\n",
      "Epoch 63/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0771 - auc: 0.9958 - val_loss: 1.6816 - val_auc: 0.7222\n",
      "Epoch 64/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.0674 - auc: 0.9968 - val_loss: 1.6978 - val_auc: 0.7222\n",
      "Epoch 65/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0840 - auc: 0.9936 - val_loss: 1.3945 - val_auc: 0.6944\n",
      "Epoch 66/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.0914 - auc: 0.9932 - val_loss: 1.5472 - val_auc: 0.7222\n",
      "Epoch 67/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.0732 - auc: 0.9963 - val_loss: 1.5706 - val_auc: 0.6944\n",
      "Epoch 68/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.0794 - auc: 0.9964 - val_loss: 1.6613 - val_auc: 0.7222\n",
      "Epoch 69/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.0805 - auc: 0.9952 - val_loss: 1.4700 - val_auc: 0.6944\n",
      "Epoch 70/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0794 - auc: 0.9964 - val_loss: 1.7082 - val_auc: 0.6806\n",
      "Epoch 71/150\n",
      "30/30 [==============================] - 6s 204ms/step - loss: 0.0690 - auc: 0.9970 - val_loss: 1.8016 - val_auc: 0.7222\n",
      "Epoch 72/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0869 - auc: 0.9952 - val_loss: 1.5715 - val_auc: 0.6944\n",
      "Epoch 73/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.0972 - auc: 0.9936 - val_loss: 1.5261 - val_auc: 0.6944\n",
      "Epoch 74/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.0700 - auc: 0.9971 - val_loss: 1.7516 - val_auc: 0.7222\n",
      "Epoch 75/150\n",
      "30/30 [==============================] - 6s 206ms/step - loss: 0.0674 - auc: 0.9973 - val_loss: 1.8084 - val_auc: 0.7222\n",
      "Epoch 76/150\n",
      "30/30 [==============================] - 6s 205ms/step - loss: 0.0824 - auc: 0.9953 - val_loss: 1.5906 - val_auc: 0.7222\n",
      "Epoch 77/150\n",
      "20/30 [===================>..........] - ETA: 1s - loss: 0.0786 - auc: 0.9959"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-15c9153f695e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAINING_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_datagen, \n",
    "    steps_per_epoch = Config.STEPS_PER_EPOCH, \n",
    "    validation_data = test_datagen, \n",
    "    validation_steps = test_images.shape[0],#Config.VALIDATION_STEPS_PER_EPOCH, \n",
    "    epochs = Config.TRAINING_EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks = [earlystop]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "mechanical-insider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 18s 358ms/step - loss: 0.1756 - auc: 0.9818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17558863759040833, 0.981806218624115]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_datagen, batch_size=64, steps=valid_images.shape[0] // 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "embedded-novel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1403 - auc: 0.5972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1403473615646362, 0.5972222685813904]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_datagen, batch_size=1, steps=test_images.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "special-payroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7222222222222222"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "roc_auc_score(test_images['class'].values, model.predict_generator(test_datagen, steps=test_images.shape[0]).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "documented-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(OUTPUT_PATH / 'models' / 'cnn_classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-journal",
   "metadata": {},
   "source": [
    "## Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fifth-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "seven-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers as L\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    \n",
    "def create_classification_model(base_model):\n",
    "    x = base_model.output\n",
    "    x = L.GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = L.Dense(512, activation='relu')(x)\n",
    "    x = L.Dense(64, activation='relu')(x)\n",
    "    # and a logistic layer -- let's say we have 200 classes\n",
    "    predictions = L.Dense(1)(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(optimizer='rmsprop', loss='mean_absolute_error', metrics = ['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "statewide-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_classification_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "adjusted-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = DataGenerator(train_images, batch_size = Config.BATCH_SIZE, is_classification = False)\n",
    "valid_datagen = DataGenerator(valid_images, batch_size = Config.BATCH_SIZE, is_classification = False)\n",
    "test_datagen = DataGenerator(test_images, batch_size = 1, is_classification = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "running-trigger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "30/30 [==============================] - 18s 508ms/step - loss: 7.6752 - mean_absolute_error: 7.6752 - val_loss: 4.9782 - val_mean_absolute_error: 4.9782\n",
      "Epoch 2/60\n",
      "30/30 [==============================] - 14s 468ms/step - loss: 5.0166 - mean_absolute_error: 5.0166 - val_loss: 3.8433 - val_mean_absolute_error: 3.8433\n",
      "Epoch 3/60\n",
      "30/30 [==============================] - 13s 449ms/step - loss: 4.3544 - mean_absolute_error: 4.3544 - val_loss: 3.8290 - val_mean_absolute_error: 3.8290\n",
      "Epoch 4/60\n",
      "30/30 [==============================] - 12s 415ms/step - loss: 4.1136 - mean_absolute_error: 4.1136 - val_loss: 3.6449 - val_mean_absolute_error: 3.6449\n",
      "Epoch 5/60\n",
      "30/30 [==============================] - 12s 415ms/step - loss: 3.4206 - mean_absolute_error: 3.4206 - val_loss: 3.5323 - val_mean_absolute_error: 3.5323\n",
      "Epoch 6/60\n",
      "30/30 [==============================] - 12s 401ms/step - loss: 3.7180 - mean_absolute_error: 3.7180 - val_loss: 3.8995 - val_mean_absolute_error: 3.8995\n",
      "Epoch 7/60\n",
      "30/30 [==============================] - 12s 398ms/step - loss: 3.1407 - mean_absolute_error: 3.1407 - val_loss: 3.1900 - val_mean_absolute_error: 3.1900\n",
      "Epoch 8/60\n",
      "30/30 [==============================] - 12s 406ms/step - loss: 3.0076 - mean_absolute_error: 3.0076 - val_loss: 3.0686 - val_mean_absolute_error: 3.0686\n",
      "Epoch 9/60\n",
      "30/30 [==============================] - 11s 384ms/step - loss: 3.1982 - mean_absolute_error: 3.1982 - val_loss: 2.7914 - val_mean_absolute_error: 2.7914\n",
      "Epoch 10/60\n",
      "30/30 [==============================] - 10s 351ms/step - loss: 3.2201 - mean_absolute_error: 3.2201 - val_loss: 2.3140 - val_mean_absolute_error: 2.3140\n",
      "Epoch 11/60\n",
      "30/30 [==============================] - 10s 323ms/step - loss: 2.9781 - mean_absolute_error: 2.9781 - val_loss: 4.1246 - val_mean_absolute_error: 4.1246\n",
      "Epoch 12/60\n",
      "30/30 [==============================] - 10s 337ms/step - loss: 2.9186 - mean_absolute_error: 2.9186 - val_loss: 2.4388 - val_mean_absolute_error: 2.4388\n",
      "Epoch 13/60\n",
      "30/30 [==============================] - 11s 358ms/step - loss: 3.2333 - mean_absolute_error: 3.2333 - val_loss: 2.3929 - val_mean_absolute_error: 2.3929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fccce4b4210>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_datagen, \n",
    "    steps_per_epoch = Config.STEPS_PER_EPOCH, \n",
    "    validation_data = valid_datagen, \n",
    "    validation_steps = Config.VALIDATION_STEPS_PER_EPOCH, \n",
    "    epochs = Config.TRAINING_EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks = [earlystop]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "exterior-carry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 10s 194ms/step - loss: 2.1932 - mean_absolute_error: 2.1932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1931848526000977, 2.1931848526000977]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_datagen, batch_size=64, steps=valid_images.shape[0] // 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "distinguished-hobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  13/3348 [..............................] - ETA: 29s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3348/3348 [==============================] - 27s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = DataGenerator(valid_images, batch_size = 1, is_classification = False, shuffle = False)\n",
    "validation_preds = model.predict_generator(valid_datagen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "charming-pearl",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2237342863545053"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "Y_pred = validation_preds.reshape(-1)\n",
    "Y_true = valid_images['energy']\n",
    "mean_absolute_error(Y_pred, Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "surgical-width",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 9ms/step - loss: 7.8741 - mean_absolute_error: 7.8741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.8741021156311035, 7.8741021156311035]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_datagen, batch_size=1, steps=test_images.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "generic-liverpool",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "test_datagen = DataGenerator(test_images, batch_size = 1, is_classification = False, shuffle = False)\n",
    "test_preds = model.predict_generator(test_datagen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "adaptive-certification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7480902622143426"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = test_preds\n",
    "Y_true = test_images['energy']\n",
    "mean_absolute_error(Y_pred, Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "grateful-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(OUTPUT_PATH / 'models' / 'cnn_energy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-booking",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bright-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, images, transform=None, batch_size=32,  shuffle=True):\n",
    "        self.images = images\n",
    "        self.indices = np.arange(len(images))\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in index]\n",
    "    \n",
    "        X = self.__get_data(batch)\n",
    "        return X\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.index)\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        X = np.zeros((self.batch_size, 150, 150, 3))\n",
    "        for i, idx in enumerate(batch):\n",
    "            image=cv2.imread(str(self.images.iloc[idx, 3]))[225:375, 225:375, :]\n",
    "            X[i,] = image\n",
    "\n",
    "        return X / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "alive-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "private_test = glob.glob(str(PRIVATE_PATH / '**/*.png'), recursive=True)\n",
    "public_test = glob.glob(str(PUBLIC_PATH / '**/*.png'), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "electric-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(INPUT_PATH / 'track1_leak.csv')\n",
    "private_ids = [t.split('/')[-1].split('.')[0] for t in private_test]\n",
    "public_ids = [t.split('/')[-1].split('.')[0] for t in public_test]\n",
    "\n",
    "sample_submission['path'] = sample_submission['id'].apply(lambda x: PRIVATE_PATH / f'{x}.png' if x in private_ids else PUBLIC_PATH / f'{x}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ancient-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_datagen = PredictDataGenerator(sample_submission, shuffle = False, batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "automated-fabric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4141/4141 [==============================] - 629s 152ms/step\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# PREDICT WITH CLASSIFICATION MODEL\n",
    "####################################\n",
    "\n",
    "cnn_classification = keras.models.load_model(OUTPUT_PATH / 'models' / 'cnn_classification')\n",
    "y_pred_class = cnn_classification.predict_generator(prediction_datagen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - [:750]\n",
    "# 1 - [750:1502]\n",
    "# 0 - [1502:7531]\n",
    "# 1 - [7531:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class.reshape(-1)[1503:7532]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "matched-north",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4141/4141 [==============================] - 111s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# PREDICT WITH REGRESSION MODEL\n",
    "####################################\n",
    "\n",
    "cnn_regression = keras.models.load_model(OUTPUT_PATH / 'models' / 'cnn_energy')\n",
    "y_pred_energy = cnn_regression.predict_generator(prediction_datagen, verbose = 1)\n",
    "y_pred_energy = np.vectorize(CLASS2ENERGY.get)(np.argmax(y_pred_energy, axis =1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "tamil-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['classification_predictions'] = (y_pred_class.reshape(-1) > 0.5).astype(int)\n",
    "sample_submission['regression_predictions'] = y_pred_energy\n",
    "sample_submission.drop(columns = ['path']).to_csv(OUTPUT_PATH / 'predictions' / 'prediction.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-burden",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
